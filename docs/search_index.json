[["CFA2nd.html", "Chapter 9 CFA: Hierarchical and Nested Models 9.1 Navigating this Lesson 9.2 CFA Workflow 9.3 Another Look at Varying Factor Structures 9.4 Revisiting Model Identification 9.5 Research Vignette 9.6 A Quick lavaan Syntax Recap 9.7 Comparing and Tweaking Multidimensional First-Order Models 9.8 An Uncorrelated Factors Model 9.9 A Correlated Factors Model 9.10 Model Respecification 9.11 Modeling the GRMSAAW as a Second-Order Structure 9.12 Modeling the GRMSAAW as a Bifactor Model 9.13 Another Look at Omega 9.14 Preparing an APA Style Results Section 9.15 A Conversation with Dr.Â Keum 9.16 Practice Problems", " Chapter 9 CFA: Hierarchical and Nested Models Screencasted Lecture Link This is the second lecture in our series on confirmatory factor analysis (CFA). Our goal is: The systematic and sequential modeling and comparing of: first-order structures (correlated v. uncorrelated factors) second-order structures bifactor structures Using modification indices to tweak each models fit (e.g., by freeing error covariances) Determining and tracking the identification status of models, including: nested/nesting models, how that impacts fit, and how comparisons are completed relative to nesting status issues of equivalent models 9.1 Navigating this Lesson The lecture is just under two hours. I would add another two-to-three hours to work through and digest the materials. While the majority of R objects and data you will need are created within the R script that sources the chapter, occasionally there are some that cannot be created from within the R framework. Additionally, sometimes links fail. All original materials are provided at the Github site that hosts the book. More detailed guidelines for ways to access all these materials are provided in the OERs introduction 9.1.1 Learning Objectives Focusing on this weeks materials, make sure you can: Specify single order (correlated and uncorrelated), second order, and bifactor models. Interpret model adequacy and fit. Compare models on the basis of statistical criteria. Determine which (among models) is the nested model. Memorize which model (nested or nesting) will have better fit (without looking at the results). Determine whether or not models (or alterations to their specification) remain statistically identified. 9.1.2 Planning for Practice In each of these lessons I provide suggestions for practice that allow you to select one or more problems that are graded in difficulty. The least complex is to change the random seed and rework the problem demonstrated in the lesson. The results should map onto the ones obtained in the lecture. The second option comes from the the back of the book where a chapter contains simulated data for all of the examples worked in this volume. Any of these is available for CFA. As a third option, you are welcome to use data to which you have access and is suitable for CFA. These could include other simualated data, data available through open science repositories, or your own data (presuming you have permissoin to use it). The suggestion for practice spans the prior chapter and this one . For this combination assignment, you should plan to: Prepare the data frame for CFA. Specify and run unidimensional, single order (with correlated facrors), second-order, and bifactor models. Narrate the adequacy of fit with \\(\\chi ^{2}\\), CFI, RMSEA, SRMR Write a mini-results section for each Compare model fit with \\(\\chi ^{2}\\Delta\\), AIC, and BIC. Write an APA style results sections with table(s) and figures. In preparing this chapter, I drew heavily from the following resource(s). Other resources are cited (when possible, linked) in the text with complete citations in the reference list. Byrne, B. M. (2016). Application 3: Testing the Factorial Validity of Scores from a Measurement Scale (Second-Order CFA model). Chapter 5. In Structural Equation Modeling with AMOS: Basic Concepts, Applications, and Programming, Third Edition. Taylor &amp; Francis Group. http://ebookcentral.proquest.com/lib/spu/detail.action?docID=4556523 Dekay, Nicole (2021). Quick Reference Guide: The statistics for psychometrics https://www.humanalysts.com/quick-reference-guide-the-statistics-for-psychometrics Flora, D. B. (2020). Your Coefficient Alpha Is Probably Wrong, but Which Coefficient Omega Is Right? A Tutorial on Using R to Obtain Better Reliability Estimates. Advances in Methods and Practices in Psychological Science, 3(4), 484501. https://doi.org/10.1177/2515245920951747 Kline, R. (2016). Principles and practice of structural equation modeling (Fourth ed., Methodology in the social sciences). New York: The Guilford Press. Chapter 6: Specification of Observed-Variable (Path Models) Chapter 7: Identification of Observed-Variable (Path) Models * Chapter 9: Specification and Identification of Confirmatory Factor Analysis Models Chapter 13: Analysis of Confirmatory Factor Analysis Models Rosseel, Y. (2019). The lavaan tutorial. Belgium: Department of Data Analysis, Ghent University. http://lavaan.ugent.be/tutorial/tutorial.pdf 9.1.3 Packages The packages used in this lesson are embedded in this code. When the hashtags are removed, the script below will (a) check to see if the following packages are installed on your computer and, if not (b) install them. #will install the package if not already installed #if(!require(lavaan)){install.packages(&quot;lavaan&quot;)} #if(!require(semPlot)){install.packages(&quot;semPlot&quot;)} #if(!require(psych)){install.packages(&quot;psych&quot;)} #if(!require(semTable)){install.packages(&quot;semTable&quot;)} #if(!require(semTools)){install.packages(&quot;semTools&quot;)} 9.2 CFA Workflow Below is a screenshot of a CFA workflow. The original document is located in the Github site that hosts the ReCentering Psych Stats: Psychometrics OER. Image of a workflow for specifying and evaluating a confirmatory factor analytic model Because the intended audience for the ReCentering Psych Stats OER is the scientist-practitioner-advocate, this lesson focuses on the workflow and decisions. As you might guess, the details of CFA can be quite complex and require more investigation and decision-making in models that pose more complexity or empirical challenges. Creating an items only dataframe where any items are scaled in the same direction (e.g., negatively worded items are reverse-scored). Determining a factor structure that is identified, that is A single factor (unidimensional) model has at least three items/indicators Multidimensional models have at least two items per factor Specify a series of models, these typicallyinclude A unidimensional model (all items on a single factor) A single order structure with correlated factors A second orer structure A bifactor structure Evaluate model fit with a variety of indicators factor loadings fit indices Compare models In the event of poor model fit, investigate modification indices and consider respecification eliminating items changing factor membership allowing errors to covary 9.3 Another Look at Varying Factor Structures In this lecture we move into second-order and bifactor models, lets look again factor structures, considering unidimensional, first-order, and second-order variations. Image of first-order, second-order, and bifactor factor structures Models A and B are first-order models. Note that all factors are on a single plane. Model A is undimensional: each item is influenced by a single common factor, and defined by a single term that includes systematic and random error. Note that there is only one systematic source of variance for each item AND it is from a single source: F1. Model B is often referred to as a correlated traits model. Here, the larger construct is separated into distinct-yet-correlated elements. The variance of each item is assumed to be a weighted linear function of two or more common factors. Model C is a second-order factor structure. Rather than merely being correlated, factors are related because they share a common cause. In this model, the second-order factor explains why three or more traits are correlated. Note that here is no direct relationship between the item and the target construct. Rather, the relationship between the second-order factor and each item is mediated through the primary factor (yes, an indirect effect!). Model D is a bifactor structure. Here, each item loads on a general factor. This general factor (bottom row) reflects what is common among the items and represents the individual differences on the target dimension that a researcher is most interested in. Group factors (top row) are now specified as orthogonal. The group factors represent common factors measured by the items that explain item response variation not accounted for by the general factor. In some research scenarios, the group factors are termed nuisance dimensions. That is, that which they have in common interferes with measuring the primary target of interest. 9.4 Revisiting Model Identification Model identification means it is theoretically possible for a statistical analysis to derive a unique estimate of every model parameter. Theoretical is emphasizes that identification is a property of the model and not the data; that is, it doesnt matter if the sample size is 100 or 10,000. CFA has the same general requirements for identification as other forms of SEM: Every latent variable (including errors) must be scaled; and Model degrees of freedom must be at least zero \\((df_{M}\\leq 0)\\) (aka the counting rule; this means that there must be at least as many observations as there are free parameters) 9.4.1 Identification Status Underidentified (or underdetermined) models violate the counting rule because there are more free parameters than observations. For example, solve this equation: \\(a + b = 6\\). There are an infinite number of solutions: 4 + 2, 3 + 3, 2.5 + 3.5and so on to \\(\\infty\\). When the computing algorithm tries to solve this problem, it will fail to converge. The parallel scenario in an SEM/CFA model with more free parameters than observations would have negative df. Just-identified (or just-determined) models have a single unique solution: \\((df_{M} = 0)\\) For example, for this set of equations: \\(a + b = 6\\) \\(2a + b = 10\\) The only answer is: \\(a = 4, b = 2\\) Overidentified (or overdetermined) models have more observations than free parameters.That is: \\((df_{M}\\gt 0)\\) For example, sovle for this set of equations: \\(a + b = 6\\) \\(2a + b = 10\\) \\(3a + b = 12\\) There is no single solution that satisfies all three formulas, but there is a way to find a unique solution. We can impose a statistical criterion that leads to the overidentified/overdetermined circumstance with more observations than free parameters. For example, we could impose the least squares criterion (from regression, but with no intercept/constant in the prediction equation). The constraint (instruction) would read: Find values of a and b that yield total scores such that the sum of squared differences between the observations (6, 10, 12) and these total scores is as small as possible (and also unique). In this case, answers are \\(a = 3.00, b = 3.33\\) and the solutions are 6.44, 9.33, 12.33. While the solution doesnt perfectly reproduce the data, it facilitates model testing. The bad news is that SEM/CFA computer tools are generally not helpful in determining whether a model is identified or not. Why? Computers are great a numerical processing, but not symbolic processing (needed for determining identification status). This means that we, the researchers, must learn the identification heuristics to determine the models degree of identification. Need a break already? My favorite scene during The Imitation Game parallels issues of identification, iterations, and convergence. The Turing machine runs and runs until its users can feed it proper start values so that it finally converges on a solution. Kenny (Kenny, 2012) provides some helpful guidelines in determining model identification with the calculation of knowns and unknowns. In in a standard CFA/SEM specification, knowns are the number of covariances between all the variables in the model, \\((k(k+1))/2\\), where \\(k\\) is the number of variables in the model. Unknowns are the free parameters that must be calculated. These include: paths; covariances between exogenous variables, between disturbances (error terms), and between exogenous variables and disturbances (error terms); variances of the exogenous variables; and disturbances (error terms) of the endogenous variables (minus the number of linear constraints). * If $knowns \\lt unknowns$ then the model is *under-identified* * If $knowns = unknowns$ then the model is *just-identified* * If $knowns \\gt unknowns$ then the model is *overidentified* 9.4.2 Identification of CFA Models Quick reminder: Every latent variable (including errors) must be scaled such that the \\((df_{M} \\geq 0)\\) Operationally, in a standard CFA model: A single factor model needs at least 3 indicators for the single factor. Factor models with more than one factor require at least two or more indicators per factor. for purposes of identification, more is better with 3-5 being recommended. (Among other things) nonstandard models occur when: errors are allowed to correlate/covary complex indicators are defined by more than one factor We will return to these as we encounter them later in todays lecture. Essentially, we will need to subtract 1 df for every parameter we free to covary, because we then need to estimate it and it becomes unknown. Empirical underidentification is also a threat. This means, the model fails to converge because of the characteristics of the data. For example, perhaps we specified model on the cusp of identification: 2 factors, correlated, with 2 indicators each. If in fact, the data did not support the correlation between the two factorsbecause of the just barely identified circumstance, you may receive an empirically underidentfied solution. Today we are going to specify second-order and bifactor models. As we do each, we will address these issues of model identification. 9.5 Research Vignette In this lesson we continue using Keum et als Gendered Racial Microaggressions Scale for Asian American Women (GRMSAAW; (Keum et al., 2018)). The article reports on separate studies that comprised the development, refinement, and psychometric evaluation of two, parallel, versions (stress appraisal, frequency) of the GRMSAAW We simulate data from the final construction of the frequency version as the basis of the lecture. If the scale looks somewhat familiar it is because the authors used the Gendered Racial Microaggressions Scale for Black Women (Lewis &amp; Neville, 2015) as a model. Keum et al. (2018) reported support for a total scale score (22 items) and four subscales. Below, I list the four subscales, their number of items, and a single example item. At the outset, let me provide a content warning. For those who hold this particular identity (or related identities) the content in the items may be upsetting. In other lessons, I often provide a variable name that gives an indication of the primary content of the item. In the case of the GRMSAAW, I will simply provide an abbreviation of the subscale name and its respective item number. This will allow us to easily inspect the alignment of the item with its intended factor, and hopefully minimize discomfort. If you are not a member of this particular identity, I encourage you to learn about these microaggressions by reading the article in its entirety. Please do not ask members of this group to explain why these microaggressions are harmful or ask if they have encountered them. There are 22 items on the GRMSAAW scale. The frequency scaling ranged included: 0(never), 1 (rarely), 2(sometimes), 3(often), 4(very frequently), and 5(always). The four factors, number of items, and sample item are as follows: Ascribed Submissiveness 9 items Others have been surprised when I disagree with them. Abbreviated in the simulated data as AS# Asian Fetishism 4 items Others have treated me as if I am always open to sexual advances. Abbreviated in the simulated data as AF# Media Invalidation 5 items I see AAW playing the same type of characters (e.g., Kung Fu woman, sidekick, mistress, tiger mom) in the media. Abbreviated in the simulated data as MI# Assumptions of Universal Appearance 4 items Others have pointed out physical traits in AAW that do not look Asian. Abbreviated in the simulated data as UA# Below I walk through the data simulation. This is not an essential portion of the lesson, but I will lecture it in case you are interested. None of the items are negatively worded (relative to the other items), so there is no need to reverse-score any items. #The GRMSAAW has two scales: frequency and stress appraisal. This simulation is for the frequency scale. set.seed(210927) GRMSAAWmat &lt;- matrix(c(.83, .79, .75, .72, .70, .69, .69, .69, .63, -.06, -.01, -.02, .21, -.03, -.04, .02, .05, .17, .05, .01, .00, -.06, .07, -.03, -.06, -.02, .08, -.06, -.01, -.03, .13, .85, .76, .75, .70, .10, -.12, -.06, .01, .06, -.06, -.04, .07, .18, -.11, -.06, .04, .02, -.03, .04, .15, .08, -.03, -.10, .11, .13, -.13, .69, .63, .61, .54, .46, -.05, -.02, .14, .14, .03, .05, -.01, -.06, .04, .08, -.13, .03, .02, .07, .06, -.11, -.02, -.08, .13, .09, -.04, -.03, .90, .79, .62, .51), ncol=4) #primary factor loadings for the four factors taken from Table 2 of the manuscript rownames(GRMSAAWmat) &lt;- c(&quot;AS1&quot;, &quot;AS2&quot;, &quot;AS3&quot;, &quot;AS4&quot;, &quot;AS5&quot;, &quot;AS6&quot;, &quot;AS7&quot;, &quot;AS8&quot;, &quot;AS9&quot;, &quot;AF1&quot;, &quot;AF2&quot;, &quot;AF3&quot;, &quot;AF4&quot;, &quot;MI1&quot;, &quot;MI2&quot;, &quot;MI3&quot;, &quot;MI4&quot;, &quot;MI5&quot;, &quot;AUA1&quot;, &quot;AUA2&quot;, &quot;AUA3&quot;, &quot;AUA4&quot;) #variable names for the items colnames(GRMSAAWmat) &lt;- c(&quot;Submissiveness&quot;, &quot;Fetishism&quot;, &quot;Media&quot;, &quot;Appearance&quot;) #component (subscale) names GRMSAAWCorMat &lt;- GRMSAAWmat %*% t(GRMSAAWmat) #create the correlation matrix via some matrix algebra diag(GRMSAAWCorMat) &lt;- 1 #SzyCorMat #prints the correlation matrix GRMSAAW_M &lt;- c(2.91, 3.3, 3.45, 2.85, 3.89, 3.11, 3.83, 3.07, 2.88, 3.3, 3.64, 3.21, 3.21, 4.2, 4.8, 4.7, 4.5, 4.89, 4.47, 4.69, 4.47, 4.45) #Means estimated from the information in Table 4. I divided the M by the number of items in each scale then &quot;jittered&quot; the number of values I needed around that mean. GRMSAAW_SD &lt;- c(1.21, 0.81, 1.34, 1.62, 1.89, 0.93, 1.01, 1.17, 1.22, 1.28, 1.47, 1.45, 1.34, 0.78, 0.93, 0.96, 0.88, 0.91, 1.13, 1.15, 1.11, 1.09) #SDs estimated from the information in Table 4. I divided the SD by the number of items in each scale then &quot;jittered&quot; the number of values I needed around that SD GRMSAAWCovMat &lt;- GRMSAAW_SD %*% t(GRMSAAW_SD) * GRMSAAWCorMat #creates a covariance matrix (with more matrix algebra) from the correlation matrix dfGRMSAAW &lt;- as.data.frame(round(MASS::mvrnorm(n=304, mu = GRMSAAW_M, Sigma = GRMSAAWCovMat, empirical = TRUE),0)) #creates the item level data from the sample size, mean, and covariance matrix; wrapped in commands to round to 0 decimal places and format as a df dfGRMSAAW[dfGRMSAAW&gt;5]&lt;-5 #restricts the upperbound of all variables to be 5 or less dfGRMSAAW[dfGRMSAAW&lt;0]&lt;-0 #resticts the lowerbound of all variable to be 0 or greater #Below is code if you would like an ID number for each case. Expecially at first, the ID number would just need to be removed, so I will not include it in the original simulation. We will add it later. #library(tidyverse) #dfGRMSAAW &lt;- dfGRMSAAW %&gt;% dplyr::mutate(ID = row_number()) #add ID to each row #dfGRMSAAW &lt;- dfGRMSAAW %&gt;%dplyr::select(ID, everything())#moving the ID number to the first column; requires Lets take a quick peek at the data to see if everthing looks correct. psych::describe(dfGRMSAAW) vars n mean sd median trimmed mad min max range skew kurtosis se AS1 1 304 2.90 1.22 3 2.91 1.48 0 5 5 -0.21 -0.48 0.07 AS2 2 304 3.28 0.84 3 3.27 1.48 1 5 4 0.06 -0.24 0.05 AS3 3 304 3.42 1.25 4 3.50 1.48 0 5 5 -0.45 -0.53 0.07 AS4 4 304 2.81 1.47 3 2.87 1.48 0 5 5 -0.22 -0.81 0.08 AS5 5 304 3.60 1.41 4 3.77 1.48 0 5 5 -0.68 -0.56 0.08 AS6 6 304 3.11 0.95 3 3.11 1.48 0 5 5 -0.13 -0.20 0.05 AS7 7 304 3.77 0.96 4 3.85 1.48 1 5 4 -0.55 -0.04 0.05 AS8 8 304 3.04 1.15 3 3.07 1.48 0 5 5 -0.28 -0.24 0.07 AS9 9 304 2.87 1.21 3 2.92 1.48 0 5 5 -0.30 -0.47 0.07 AF1 10 304 3.25 1.24 3 3.32 1.48 0 5 5 -0.30 -0.61 0.07 AF2 11 304 3.52 1.23 4 3.62 1.48 0 5 5 -0.52 -0.41 0.07 AF3 12 304 3.17 1.32 3 3.25 1.48 0 5 5 -0.32 -0.70 0.08 AF4 13 304 3.15 1.27 3 3.20 1.48 0 5 5 -0.23 -0.77 0.07 MI1 14 304 4.15 0.75 4 4.21 1.48 2 5 3 -0.49 -0.40 0.04 MI2 15 304 4.51 0.68 5 4.64 0.00 2 5 3 -1.24 0.96 0.04 MI3 16 304 4.47 0.72 5 4.60 0.00 2 5 3 -1.18 0.68 0.04 MI4 17 304 4.35 0.75 4 4.45 1.48 2 5 3 -0.89 0.13 0.04 MI5 18 304 4.61 0.63 5 4.72 0.00 2 5 3 -1.41 1.17 0.04 AUA1 19 304 4.24 0.84 4 4.34 1.48 1 5 4 -0.88 0.19 0.05 AUA2 20 304 4.38 0.80 5 4.51 0.00 1 5 4 -1.21 1.07 0.05 AUA3 21 304 4.27 0.86 4 4.39 1.48 1 5 4 -1.05 0.64 0.05 AUA4 22 304 4.24 0.86 4 4.36 1.48 2 5 3 -0.89 -0.12 0.05 The optional script below will let you save the simulated data to your computing environment as either a .csv file (think Excel lite) or .rds object (preserves any formatting you might do). If you save the .csv file and bring it back in, you will lose any formatting (e.g., ordered factors will be interpreted as character variables). #write the simulated data as a .csv #write.table(dfGRMSAAW, file=&quot;dfGRMSAAW.csv&quot;, sep=&quot;,&quot;, col.names=TRUE, row.names=FALSE) #bring back the simulated dat from a .csv file #dfGRMSAAW &lt;- read.csv (&quot;dfGRMSAAW.csv&quot;, header = TRUE) An .rds file preserves all formatting to variables prior to the export and re-import. For the purpose of this chapter, you dont need to do either. That is, you can re-simulate the data each time you work the problem. #to save the df as an .rds (think &quot;R object&quot;) file on your computer; it should save in the same file as the .rmd file you are working with #saveRDS(dfGRMSAAW, &quot;dfGRMSAAW.rds&quot;) #bring back the simulated dat from an .rds file #dfGRMSAAW &lt;- readRDS(&quot;dfGRMSAAW.rds&quot;) 9.6 A Quick lavaan Syntax Recap Its really just regression tilda (~, is regressed on) is the regression operator place DV (y) on left side of the regression operator place IVs, separated by +, on the right of the regression operator f is a latent variable (LV) Example: y ~ f1 + f2 + x1 + x2 LVs must be defined by their manifest or latent indicators. the special operator (=~, is measured/defined by) is used for this Example: f1 =~ y1 + y2 + y3 Variances and covariances are specified with a double tilde operator (~~, is correlated with) Example of variance: y1 ~~ y1 (variables relationship with itself) Example of covariance: y1 ~~ y2 (relationship with another variable) Example of covariance of a factor: f1 ~~ f2 Intercepts (~ 1) for observed variables and LVs are simple, intercept-only regression formulas. Example of variable intercept: y1 ~ 1 Example of factor intercept: f1 ~ 1 A complete lavaan model is a combination of these formula types, enclosed between single quotation marks. Readability of model syntax is improved by: splitting formulas over multiple lines using blank lines within single quote labeling with the hashtag CFAmodel &lt;-  f1 =~ y1 + y2 + y3 f2 =~ y4 + y5 + y6 f3 =~ y7 + y8 + y9 + y10  Behind the scenes the cfa() function: fixes the factor loading of the first indicator of an LV to 1 (setting the scale) automatically adds residual variances (required) correlates all exogenous LVs; to turn these off add the following statement to the cfa() function statement: orthogonal = TRUE 9.7 Comparing and Tweaking Multidimensional First-Order Models In the prior lesson we examined unidimensional and multidimensional variants of the GRMSAAW. Our work determined that the first-order structure that included four correlated factors was superior to a unidimensional measure. Starting with the multidimensional model (four factors), lets specify both correlated and uncorrelated options and compare them. Well choose the best and see if we can further tweak it into acceptable fit. 9.8 An Uncorrelated Factors Model 9.8.1 Specifying the Model In the absence of a more complex (e.g,. second-order) structure, lavaans cfa() function automatically correlates first-order factors. However, the more parsimonious model is one with uncorrelated factors. Well run it first. To do so, we need to turn off the default so that factors will be uncorrelated. This is accomplished in the cfa() function script with orthogonal = TRUE grmsAAW4mod &lt;- &#39;AS =~ AS1 + AS2 + AS3 + AS4 + AS5 + AS6 + AS7 + AS8 + AS9 AF =~ AF1 + AF2 + AF3 + AF4 MI =~ MI1 + MI2 + MI3 + MI4 + MI5 AUA =~ AUA1 + AUA2 + AUA3 + AUA4&#39; grmsAAW4mod [1] &quot;AS =~ AS1 + AS2 + AS3 + AS4 + AS5 + AS6 + AS7 + AS8 + AS9\\n AF =~ AF1 + AF2 + AF3 + AF4 \\n MI =~ MI1 + MI2 + MI3 + MI4 + MI5\\n AUA =~ AUA1 + AUA2 + AUA3 + AUA4&quot; #next, use the cfa function to apply the model to the data uncorrF &lt;- lavaan::cfa(grmsAAW4mod, data = dfGRMSAAW, orthogonal = TRUE) lavaan::summary(uncorrF, fit.measures = TRUE, standardized = TRUE, rsquare = TRUE) lavaan 0.6-9 ended normally after 36 iterations Estimator ML Optimization method NLMINB Number of model parameters 44 Number of observations 304 Model Test User Model: Test statistic 223.701 Degrees of freedom 209 P-value (Chi-square) 0.231 Model Test Baseline Model: Test statistic 2114.899 Degrees of freedom 231 P-value 0.000 User Model versus Baseline Model: Comparative Fit Index (CFI) 0.992 Tucker-Lewis Index (TLI) 0.991 Loglikelihood and Information Criteria: Loglikelihood user model (H0) -8443.297 Loglikelihood unrestricted model (H1) -8331.446 Akaike (AIC) 16974.593 Bayesian (BIC) 17138.143 Sample-size adjusted Bayesian (BIC) 16998.597 Root Mean Square Error of Approximation: RMSEA 0.015 90 Percent confidence interval - lower 0.000 90 Percent confidence interval - upper 0.029 P-value RMSEA &lt;= 0.05 1.000 Standardized Root Mean Square Residual: SRMR 0.062 Parameter Estimates: Standard errors Standard Information Expected Information saturated (h1) model Structured Latent Variables: Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all AS =~ AS1 1.000 0.972 0.799 AS2 0.626 0.047 13.238 0.000 0.609 0.724 AS3 0.911 0.070 12.962 0.000 0.886 0.711 AS4 1.083 0.083 13.059 0.000 1.053 0.716 AS5 0.965 0.081 11.963 0.000 0.938 0.665 AS6 0.625 0.055 11.385 0.000 0.608 0.638 AS7 0.657 0.055 12.009 0.000 0.638 0.667 AS8 0.754 0.066 11.388 0.000 0.733 0.638 AS9 0.734 0.070 10.428 0.000 0.714 0.591 AF =~ AF1 1.000 1.010 0.818 AF2 0.831 0.076 10.948 0.000 0.839 0.680 AF3 0.942 0.082 11.516 0.000 0.951 0.723 AF4 0.803 0.078 10.308 0.000 0.811 0.638 MI =~ MI1 1.000 0.466 0.621 MI2 0.797 0.137 5.820 0.000 0.371 0.547 MI3 0.766 0.138 5.565 0.000 0.357 0.496 MI4 0.767 0.140 5.463 0.000 0.357 0.480 MI5 0.474 0.107 4.421 0.000 0.221 0.354 AUA =~ AUA1 1.000 0.684 0.820 AUA2 0.874 0.090 9.764 0.000 0.598 0.749 AUA3 0.630 0.083 7.589 0.000 0.430 0.501 AUA4 0.623 0.083 7.493 0.000 0.426 0.494 Covariances: Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all AS ~~ AF 0.000 0.000 0.000 MI 0.000 0.000 0.000 AUA 0.000 0.000 0.000 AF ~~ MI 0.000 0.000 0.000 AUA 0.000 0.000 0.000 MI ~~ AUA 0.000 0.000 0.000 Variances: Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all .AS1 0.534 0.055 9.711 0.000 0.534 0.361 .AS2 0.337 0.031 10.707 0.000 0.337 0.476 .AS3 0.767 0.071 10.821 0.000 0.767 0.494 .AS4 1.057 0.098 10.782 0.000 1.057 0.488 .AS5 1.110 0.099 11.163 0.000 1.110 0.558 .AS6 0.539 0.048 11.322 0.000 0.539 0.594 .AS7 0.508 0.046 11.149 0.000 0.508 0.555 .AS8 0.784 0.069 11.322 0.000 0.784 0.593 .AS9 0.951 0.082 11.542 0.000 0.951 0.651 .AF1 0.505 0.076 6.666 0.000 0.505 0.332 .AF2 0.816 0.082 9.893 0.000 0.816 0.537 .AF3 0.825 0.090 9.158 0.000 0.825 0.477 .AF4 0.956 0.092 10.416 0.000 0.956 0.593 .MI1 0.345 0.044 7.890 0.000 0.345 0.614 .MI2 0.322 0.035 9.293 0.000 0.322 0.700 .MI3 0.391 0.039 10.042 0.000 0.391 0.754 .MI4 0.427 0.042 10.240 0.000 0.427 0.770 .MI5 0.341 0.030 11.349 0.000 0.341 0.875 .AUA1 0.228 0.044 5.152 0.000 0.228 0.328 .AUA2 0.280 0.039 7.258 0.000 0.280 0.439 .AUA3 0.553 0.049 11.237 0.000 0.553 0.749 .AUA4 0.562 0.050 11.279 0.000 0.562 0.756 AS 0.946 0.117 8.085 0.000 1.000 1.000 AF 1.019 0.133 7.664 0.000 1.000 1.000 MI 0.217 0.049 4.408 0.000 1.000 1.000 AUA 0.467 0.067 6.996 0.000 1.000 1.000 R-Square: Estimate AS1 0.639 AS2 0.524 AS3 0.506 AS4 0.512 AS5 0.442 AS6 0.406 AS7 0.445 AS8 0.407 AS9 0.349 AF1 0.668 AF2 0.463 AF3 0.523 AF4 0.407 MI1 0.386 MI2 0.300 MI3 0.246 MI4 0.230 MI5 0.125 AUA1 0.672 AUA2 0.561 AUA3 0.251 AUA4 0.244 9.8.2 Interpreting the Output Criteria Our Results Criteria met? Factor loadings significant, strong, proper valence AS: .59 to .80; AF: .64 to .82; MI: .35 to .62; AUA: .49 to .82 Yes Non-significant chi-square \\(\\chi ^{2}(209) = 223.70, p = .231\\) Yes \\(CFI\\geq .95\\) CFI = .992 Yes \\(RMSEA\\leq .05\\) (but definitely &lt; .10) RMSEA = .015, 90%CI(.000, .029) Yes \\(SRMR\\leq .08\\) (but definitely &lt; .10) SRMS = .062 Yes(with caution) Combination rule: \\(CFI \\geq .95\\) and \\(SRMR \\leq .08\\) CFI = .992, SRS = .072 Yes 9.8.3 Partial Write-up Uncorrelated factors model. The model where factors were fixed to remain uncorrelated demonstrated adequate fit to the data: \\(\\chi ^{2}(209) = 223.70, p = .231\\), CFI = .99, RMSEA = .015, 90%CI(.000, .029), SRMR = .062. Factor loadings ranged from .59 to .80 for the AS scale, .64 to .82 for the AF scale, .35 to .62 for the MI scale, and .49 to .82 for the fear of AUA scale. Producing a figure can be useful to represent what we did to others as well as checking our own work. That is, Did we think we did what we intended? When the *what = col, whatLabels = stand) combination is shown, paths that are fixed are represented by dashed lines. Below, we expect to see each the four factors predicting only the items associated with their factor, one item for each factor (the first on the left) should be specified as the indicator variable (and represented with a dashed line), and the factors/latent variables should not be freed to covary (i.e., an uncorrelated traits or orthogonal model). Because they are fixed to be 0.00, they will be represented with dashed curves with double-headed arrows. semPlot::semPaths(uncorrF, layout = &quot;tree&quot;, style = &quot;lisrel&quot;, what = &quot;col&quot;, whatLabels = &quot;stand&quot;) Although this fit is reasonable, the correlated factors model should have a better fit. Instead of tweaking this one, lets move onto the correlated factors model. 9.9 A Correlated Factors Model Lets revisit the statement I just made: the correlated factors model should have a better fit. Why did I make this statement? Its all about degrees of freedom and whether the model is the nested or nesting model. 9.9.1 Nested Models When we specify (i.e., draw) models in SEM/CFA, we often think that the paths (single headed arrows/paths, double-headed arrows/covariances) between the parameters are our hypotheses. They are, but they are soft hypotheses in that we are freeing the elements to covary. The hard hypotheses (i.e., no paths, no covariances) are that the parameters are unrelated. We are trying to explain the covariance matrix (where all parameters are freed to covary) with the fewest paths possible: freeing the relations between our hypothesized parameters and restricting all others to be zero. Two models are nested (aka hierarchical) if one is a proper subset of the other. The nesting model is the one with the most parameters freed to covary. That is, it has more paths/covariances drawn on it. Almost always, the nesting model (i.e., most sticks, fewer degrees of freedom) will have better fit than the nested model (i.e., fewer sticks, more degrees of freedom). In our example, uncorrF has four uncorrelated factors and its degrees of freedom was 209. Our new model will add covariances (making it the nesting model with presumed better fit) to all possible combinations of the four factors (we end up with 6 covariance paths). Freeing these additional factors to covary in the corrF model (recall they were fixed to 0.0 in the uncorrF model) leads to a model with 203 degrees of freedom. The degrees of freedom are lower because the algorithm now needs to estimate 6 additional covariances/parameters (i.e., \\(209 - 6 = 203\\)). Model fit (generally) improves when paths/covariances are added (and degrees of freedom decreases). The model with the most paths (I think of sticks in a nest) and the fewest df is the nesting model and it (almost) always has superior fit. Lets try. #in our 4-factor models we can use the same baseM, the difference here is that we deleted &quot;orthogonal = TRUE&quot; #uncorrF &lt;- lavaan::cfa(grmsAAW4mod, data = dfGRMSAAW, orthogonal = TRUE) #for comparison, this was the uncorrelated model corrF &lt;- lavaan::cfa (grmsAAW4mod, data = dfGRMSAAW) lavaan::summary(corrF, fit.measures = TRUE, standardized = TRUE, rsquare = TRUE) lavaan 0.6-9 ended normally after 37 iterations Estimator ML Optimization method NLMINB Number of model parameters 50 Number of observations 304 Model Test User Model: Test statistic 220.858 Degrees of freedom 203 P-value (Chi-square) 0.186 Model Test Baseline Model: Test statistic 2114.899 Degrees of freedom 231 P-value 0.000 User Model versus Baseline Model: Comparative Fit Index (CFI) 0.991 Tucker-Lewis Index (TLI) 0.989 Loglikelihood and Information Criteria: Loglikelihood user model (H0) -8441.875 Loglikelihood unrestricted model (H1) -8331.446 Akaike (AIC) 16983.750 Bayesian (BIC) 17169.602 Sample-size adjusted Bayesian (BIC) 17011.027 Root Mean Square Error of Approximation: RMSEA 0.017 90 Percent confidence interval - lower 0.000 90 Percent confidence interval - upper 0.031 P-value RMSEA &lt;= 0.05 1.000 Standardized Root Mean Square Residual: SRMR 0.058 Parameter Estimates: Standard errors Standard Information Expected Information saturated (h1) model Structured Latent Variables: Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all AS =~ AS1 1.000 0.971 0.799 AS2 0.626 0.047 13.211 0.000 0.608 0.723 AS3 0.912 0.070 12.953 0.000 0.886 0.711 AS4 1.084 0.083 13.047 0.000 1.053 0.716 AS5 0.966 0.081 11.955 0.000 0.938 0.665 AS6 0.626 0.055 11.389 0.000 0.608 0.638 AS7 0.658 0.055 12.006 0.000 0.639 0.667 AS8 0.755 0.066 11.393 0.000 0.734 0.638 AS9 0.735 0.071 10.427 0.000 0.714 0.591 AF =~ AF1 1.000 1.014 0.821 AF2 0.824 0.075 10.935 0.000 0.836 0.678 AF3 0.932 0.081 11.487 0.000 0.945 0.719 AF4 0.802 0.077 10.369 0.000 0.814 0.641 MI =~ MI1 1.000 0.449 0.599 MI2 0.848 0.145 5.847 0.000 0.381 0.561 MI3 0.812 0.145 5.595 0.000 0.365 0.506 MI4 0.797 0.147 5.439 0.000 0.358 0.481 MI5 0.491 0.112 4.395 0.000 0.220 0.353 AUA =~ AUA1 1.000 0.682 0.818 AUA2 0.875 0.089 9.786 0.000 0.597 0.748 AUA3 0.634 0.083 7.619 0.000 0.432 0.503 AUA4 0.628 0.083 7.537 0.000 0.429 0.497 Covariances: Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all AS ~~ AF 0.017 0.066 0.262 0.794 0.017 0.017 MI 0.036 0.033 1.072 0.284 0.082 0.082 AUA 0.023 0.045 0.520 0.603 0.035 0.035 AF ~~ MI -0.028 0.036 -0.764 0.445 -0.060 -0.060 AUA 0.012 0.049 0.236 0.814 0.017 0.017 MI ~~ AUA 0.024 0.025 0.960 0.337 0.077 0.077 Variances: Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all .AS1 0.536 0.055 9.727 0.000 0.536 0.362 .AS2 0.338 0.032 10.713 0.000 0.338 0.477 .AS3 0.767 0.071 10.819 0.000 0.767 0.494 .AS4 1.057 0.098 10.781 0.000 1.057 0.488 .AS5 1.110 0.099 11.162 0.000 1.110 0.558 .AS6 0.539 0.048 11.319 0.000 0.539 0.593 .AS7 0.508 0.046 11.147 0.000 0.508 0.554 .AS8 0.783 0.069 11.318 0.000 0.783 0.593 .AS9 0.950 0.082 11.540 0.000 0.950 0.651 .AF1 0.496 0.076 6.550 0.000 0.496 0.326 .AF2 0.821 0.083 9.934 0.000 0.821 0.540 .AF3 0.836 0.090 9.249 0.000 0.836 0.483 .AF4 0.951 0.091 10.395 0.000 0.951 0.589 .MI1 0.361 0.043 8.381 0.000 0.361 0.641 .MI2 0.315 0.035 9.074 0.000 0.315 0.685 .MI3 0.386 0.039 9.915 0.000 0.386 0.744 .MI4 0.427 0.042 10.233 0.000 0.427 0.769 .MI5 0.342 0.030 11.352 0.000 0.342 0.875 .AUA1 0.230 0.044 5.228 0.000 0.230 0.331 .AUA2 0.281 0.038 7.300 0.000 0.281 0.441 .AUA3 0.551 0.049 11.221 0.000 0.551 0.747 .AUA4 0.560 0.050 11.257 0.000 0.560 0.753 AS 0.944 0.117 8.073 0.000 1.000 1.000 AF 1.028 0.133 7.709 0.000 1.000 1.000 MI 0.202 0.047 4.279 0.000 1.000 1.000 AUA 0.465 0.067 6.992 0.000 1.000 1.000 R-Square: Estimate AS1 0.638 AS2 0.523 AS3 0.506 AS4 0.512 AS5 0.442 AS6 0.407 AS7 0.446 AS8 0.407 AS9 0.349 AF1 0.674 AF2 0.460 AF3 0.517 AF4 0.411 MI1 0.359 MI2 0.315 MI3 0.256 MI4 0.231 MI5 0.125 AUA1 0.669 AUA2 0.559 AUA3 0.253 AUA4 0.247 9.9.2 Interpreting the Output Criteria Our Results Criteria met? Factor loadings significant, strong, proper valence 59 to .80; AF: .64 to .82; MI: .35 to .60; AUA: .50 to .82 Yes Non-significant chi-square \\(\\chi ^{2}(203) = 220.86, p = .186\\) Yes \\(CFI\\geq .95\\) CFI = .991 Yes \\(RMSEA\\leq .05\\) (but definitely &lt; .10) RMSEA = .017, 90%CI(.000, .031) Yes \\(SRMR\\leq .08\\) (but definitely &lt; .10) SRMR = .058 Yes Combination rule: \\(CFI \\geq .95\\) and \\(SRMR \\leq .08\\) CFI = .991, SRS = .058 Yes 9.9.3 Partial Write-up Uncorrelated factors model. The model where factors were fixed to remain uncorrelated demonstrated adequate fit to the data: \\(\\chi ^{2}(203) = 220.86, p = .186\\), CFI = .99, RMSEA = .017, 90%CI(.000, .031), SRMR = .058. Factor loadings ranged from .59 to .80 for the AS scale, .64 to .82 for the AF scale, .35 to .60 for the MI scale, and .50 to .82 for the fear of AUA scale. As we plot this model we expect to see each of the four factors predicting only the items associated with their factor, one item for each factor (the first on the left) specified as the indicator variable, and double-headed arrows between the factors/latent variables, indicating that they are free to covary (i.e., a correlated traits model). semPlot::semPaths(corrF, layout = &quot;tree&quot;, style = &quot;lisrel&quot;, what = &quot;col&quot;, whatLabels = &quot;stand&quot;) Recall that we can formally compare these models with the \\(\\chi_{D}^{2}\\), AIC, and BIC. lavaan::lavTestLRT(uncorrF, corrF) Chi-Squared Difference Test Df AIC BIC Chisq Chisq diff Df diff Pr(&gt;Chisq) corrF 203 16984 17170 220.86 uncorrF 209 16975 17138 223.70 2.8432 6 0.8283 The AIC and BIC are flexible to compare nested and non-nested models. Models with the lower values are superior. Curiously, and contrary to what we expect (i.e., the nesting model [the model with the most parameters and fewest degrees of freedom] should be superior), the AIC and BIC favor the uncorrelated factors model. The \\(\\chi_{D}^{2}\\) can only be used for nested models (where items/indicators are identical  the only difference is the presence/absence of parameters). If it is statistically significant, the better model is the one with the lower chi-square value (and better fit indices). In this particular comparison there is not a statistically significant difference. These findings are atypical and likely due to data I simulated from Keum et al. (2018). Specifically, the data was simulated from pattern coefficients (e.g., factor loadings) from the parallel analysis (EFA). This factor analytic process would have created factor loadings that were as distinct (orthogonal, uncorrelated) as possible. Thus, our simulation creates a rather pristine set of data for re-analysis. To recap the highlights of nesting, the nesting model will usually have the best fit. The nesting model has: the most free parameters (the most sticks) the fewest degrees of freedom Side by side comparison of uncorrelated and correlated models Examining the two models we compared side-by-side (uncorrelated on left; correlated on right), we can visualize the additional sticks (i.e., the covariances that were freed) in the correlated factors model and guess (without looking) that it because it has (a) fewer degrees of freedom, it will have (b) better fit. How to keep them straight: the nested is within (or sits in or fits in) the nesting model. Just keep saying it until it sticks (bad pun intended). 9.10 Model Respecification Our uncorrelated and correlated factors models have excellent fit, but this is not always the case. One way to improve model fit is to add parameters to simpler models  this is called model building. This can only occur for models that are overidentified (i.e., they have positive degrees of freedom). In the CFA/psychometric case, an overidentified model is one that has at least 3 items per scale for a unidimensional factor structure and at least 2 items per scale in a multidimensional factor structure. As we free each parameter (i.e., add paths or covariances), we correspondingly decrease the df. So we must be diligent when engaging in model building. In the CFA/psychometric case, freeing parameters usually means one of two things. Allowing cross-loadings. This would mean that an item belongs to two factors/scales. While this might be theoretically defensible, items that belong to more than one scale cause scoring difficulties when the scale is put into practice. Allowing the error variances of indicators to correlate. This would mean that there is something in common about the two items that is not explained/caused by the items relationship(s) with their respective factor(s). There are a variety of reasons this could occur, perhaps they have a content element that is in common, but different than the factor to which they belong. Methods factors (e.g., reverse scored items) can also contribute to items being correlated. We use modification indices as a guide to determine if an error covariance is worth freeing. Modification indices tell you the degree to which your chi-square value will drop if the relationship between the two parameters are freed to relate (either a path or a covariance). Generally, a 1 degree of freedom change in a model will be a statistically significant difference if the chi-square value drops by 4 points. This is purely a statistical test that you have to then discern: if allowing the two elements to relate is theoretically defensible;; if there is truly something reasonably in common that is different from the theorized relations with the factors Although many psychometricians frown on this, I think it, minimally, makes good diagnostic sense to take a look. lavaan::modindices(corrF, sort=TRUE, minimum.value = 4) lhs op rhs mi epc sepc.lv sepc.all sepc.nox 58 AS =~ AF4 23.028 0.317 0.308 0.242 0.242 97 MI =~ AF3 12.480 0.586 0.263 0.200 0.200 298 AF3 ~~ MI1 12.241 0.137 0.137 0.250 0.250 95 MI =~ AF1 10.763 -0.494 -0.222 -0.180 -0.180 116 AUA =~ MI1 8.611 -0.201 -0.137 -0.183 -0.183 76 AF =~ AS9 8.120 0.179 0.181 0.150 0.150 78 AF =~ MI2 7.700 -0.113 -0.114 -0.169 -0.169 86 MI =~ AS1 7.630 -0.363 -0.163 -0.134 -0.134 85 AF =~ AUA4 7.523 0.134 0.135 0.157 0.157 96 MI =~ AF2 6.572 0.409 0.184 0.149 0.149 77 AF =~ MI1 6.560 0.116 0.117 0.157 0.157 320 MI1 ~~ AUA1 5.644 -0.058 -0.058 -0.200 -0.200 98 MI =~ AF4 5.598 -0.399 -0.179 -0.141 -0.141 55 AS =~ AF1 5.092 -0.133 -0.129 -0.105 -0.105 109 AUA =~ AS7 4.996 -0.158 -0.108 -0.112 -0.112 114 AUA =~ AF3 4.473 -0.207 -0.141 -0.107 -0.107 108 AUA =~ AS6 4.294 0.149 0.102 0.107 0.107 63 AS =~ MI5 4.263 0.079 0.077 0.123 0.123 117 AUA =~ MI2 4.153 0.126 0.086 0.126 0.126 92 MI =~ AS7 4.135 0.243 0.109 0.114 0.114 288 AF2 ~~ MI1 4.091 0.077 0.077 0.141 0.141 9.10.1 Respecifying a Cross-Loading When we inspect the modification indices output, we are: inspecting (and perhaps acting on) at the highest mi value, one at a time seeing if that value seems a substantially higher than the next highest value In our dataset, allowing AF4 to crossload on the AF and AS factors will reduce the \\(\\chi_^{2}\\) by 23 points; the next highest modification indices are 12. Recall, a 1 degree of freedom change in a model will be a statistically significant difference if the chi-square value drops by 4 points, so we can expect this to make a statistically significant difference. Next, we must inspect the relationship to see if we could justify connecting them through a path or covariance. The item in question is AF4: Others have treated me as if I am always open to sexual advances. The modification index tells us that model fit will be incrementally improved if we free this to crossload on the Ascribed Submissiveness factor (it is presently on the Asian Fetishism factor). Statistical indices like these often help researchers understand their items in new ways. Were this my data, I would be happy with these results and not respecify the model. However, because this is a teaching lesson, I will demonstrate the respecification and evaluation. ModInd_M1 &lt;- &#39;AS =~ AS1 + AS2 + AS3 + AS4 + AS5 + AS6 + AS7 + AS8 + AS9 + AF4 AF =~ AF1 + AF2 + AF3 + AF4 MI =~ MI1 + MI2 + MI3 + MI4 + MI5 AUA =~ AUA1 + AUA2 + AUA3 + AUA4&#39; ModInd_M1 [1] &quot;AS =~ AS1 + AS2 + AS3 + AS4 + AS5 + AS6 + AS7 + AS8 + AS9 + AF4\\n AF =~ AF1 + AF2 + AF3 + AF4 \\n MI =~ MI1 + MI2 + MI3 + MI4 + MI5\\n AUA =~ AUA1 + AUA2 + AUA3 + AUA4&quot; Well give our respecified model a new object name and run it. Because we have added a path (allowing the cross-loading), this becomes the nesting model (it has the most paths and the fewest degrees of freedom). ModInd_M1f &lt;- lavaan::cfa(ModInd_M1, data = dfGRMSAAW) lavaan::summary(ModInd_M1f, fit.measures = TRUE, standardized = TRUE) lavaan 0.6-9 ended normally after 38 iterations Estimator ML Optimization method NLMINB Number of model parameters 51 Number of observations 304 Model Test User Model: Test statistic 196.883 Degrees of freedom 202 P-value (Chi-square) 0.588 Model Test Baseline Model: Test statistic 2114.899 Degrees of freedom 231 P-value 0.000 User Model versus Baseline Model: Comparative Fit Index (CFI) 1.000 Tucker-Lewis Index (TLI) 1.003 Loglikelihood and Information Criteria: Loglikelihood user model (H0) -8429.887 Loglikelihood unrestricted model (H1) -8331.446 Akaike (AIC) 16961.774 Bayesian (BIC) 17151.343 Sample-size adjusted Bayesian (BIC) 16989.597 Root Mean Square Error of Approximation: RMSEA 0.000 90 Percent confidence interval - lower 0.000 90 Percent confidence interval - upper 0.023 P-value RMSEA &lt;= 0.05 1.000 Standardized Root Mean Square Residual: SRMR 0.051 Parameter Estimates: Standard errors Standard Information Expected Information saturated (h1) model Structured Latent Variables: Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all AS =~ AS1 1.000 0.974 0.800 AS2 0.625 0.047 13.261 0.000 0.608 0.723 AS3 0.910 0.070 12.998 0.000 0.886 0.711 AS4 1.080 0.083 13.075 0.000 1.052 0.715 AS5 0.963 0.080 11.984 0.000 0.938 0.665 AS6 0.625 0.055 11.420 0.000 0.608 0.638 AS7 0.654 0.054 12.000 0.000 0.637 0.665 AS8 0.754 0.066 11.430 0.000 0.734 0.639 AS9 0.735 0.070 10.468 0.000 0.715 0.592 AF4 0.317 0.065 4.879 0.000 0.309 0.243 AF =~ AF1 1.000 1.020 0.826 AF2 0.814 0.074 11.000 0.000 0.830 0.674 AF3 0.924 0.080 11.624 0.000 0.943 0.717 AF4 0.808 0.075 10.811 0.000 0.824 0.649 MI =~ MI1 1.000 0.449 0.598 MI2 0.851 0.145 5.849 0.000 0.382 0.563 MI3 0.813 0.145 5.596 0.000 0.365 0.506 MI4 0.798 0.147 5.436 0.000 0.358 0.480 MI5 0.490 0.112 4.385 0.000 0.220 0.352 AUA =~ AUA1 1.000 0.682 0.818 AUA2 0.875 0.089 9.786 0.000 0.597 0.748 AUA3 0.634 0.083 7.619 0.000 0.432 0.503 AUA4 0.628 0.083 7.537 0.000 0.429 0.497 Covariances: Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all AS ~~ AF -0.039 0.067 -0.573 0.567 -0.039 -0.039 MI 0.032 0.033 0.968 0.333 0.074 0.074 AUA 0.023 0.045 0.510 0.610 0.035 0.035 AF ~~ MI -0.033 0.036 -0.903 0.367 -0.071 -0.071 AUA 0.010 0.049 0.212 0.832 0.015 0.015 MI ~~ AUA 0.024 0.025 0.965 0.335 0.078 0.078 Variances: Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all .AS1 0.532 0.055 9.724 0.000 0.532 0.359 .AS2 0.338 0.031 10.732 0.000 0.338 0.477 .AS3 0.767 0.071 10.838 0.000 0.767 0.494 .AS4 1.059 0.098 10.808 0.000 1.059 0.489 .AS5 1.111 0.099 11.179 0.000 1.111 0.558 .AS6 0.539 0.048 11.332 0.000 0.539 0.593 .AS7 0.510 0.046 11.174 0.000 0.510 0.557 .AS8 0.782 0.069 11.329 0.000 0.782 0.592 .AS9 0.949 0.082 11.547 0.000 0.949 0.650 .AF4 0.858 0.085 10.071 0.000 0.858 0.532 .AF1 0.484 0.074 6.503 0.000 0.484 0.317 .AF2 0.830 0.082 10.059 0.000 0.830 0.546 .AF3 0.840 0.090 9.371 0.000 0.840 0.486 .MI1 0.361 0.043 8.396 0.000 0.361 0.642 .MI2 0.315 0.035 9.053 0.000 0.315 0.684 .MI3 0.386 0.039 9.910 0.000 0.386 0.743 .MI4 0.427 0.042 10.236 0.000 0.427 0.769 .MI5 0.342 0.030 11.357 0.000 0.342 0.876 .AUA1 0.230 0.044 5.228 0.000 0.230 0.331 .AUA2 0.281 0.038 7.301 0.000 0.281 0.441 .AUA3 0.551 0.049 11.221 0.000 0.551 0.747 .AUA4 0.560 0.050 11.256 0.000 0.560 0.753 AS 0.948 0.117 8.108 0.000 1.000 1.000 AF 1.041 0.133 7.814 0.000 1.000 1.000 MI 0.201 0.047 4.273 0.000 1.000 1.000 AUA 0.465 0.067 6.992 0.000 1.000 1.000 9.10.1.1 Interpreting the Output Criteria Our Results Criteria met? Factor loadings significant, strong, proper valence AS: .24 to .80; AF: .65 to .83; MI: .35 to .60; AUA: .50 to .82 The cross-loaded item is really low (.24) Non-significant chi-square \\(\\chi ^{2} (202) = 196.883, p = .588\\) Yes \\(CFI\\geq .95\\) CFI = 1.000 Yes \\(RMSEA\\leq .05\\) (but definitely &lt; .10) RMSEA = .000, 90%CI(.000, .023) Yes \\(SRMR\\leq .08\\) (but definitely &lt; .10) SRMR = .051 Yes Combination rule: \\(CFI \\geq .95\\) and \\(SRMR \\leq .08\\) CFI = 1.000, SRMR = .051 Yes We can formally test the difference in models: lavaan::lavTestLRT(uncorrF, corrF, ModInd_M1f) Chi-Squared Difference Test Df AIC BIC Chisq Chisq diff Df diff Pr(&gt;Chisq) ModInd_M1f 202 16962 17151 196.88 corrF 203 16984 17170 220.86 23.9756 1 0.0000009756 *** uncorrF 209 16975 17138 223.70 2.8432 6 0.8283 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 We see that the difference between ModInd_M1f and corrF is statistically significant and that the AIC and BIC are lower (more favorable) for the respecified model. Because our fit indices were already strong, the cross-loading value is low, and it makes a mess of scoring and interpretation, we will not retain this model and I will not write it up. However, we can learn some things from it: The cross-loading is not strong. As predicted freeing one parameter improved model fit. The respecified model with the additional parameter is the nesting model. Just because there is statistical support for freeing a parameter, there must be strong rationale for doing so. Although a little tough to see, AF4 is cross-loaded onto two factors, AS and AF. semPlot::semPaths(ModInd_M1f, layout = &quot;tree&quot;, style = &quot;lisrel&quot;, what = &quot;col&quot;, whatLabels = &quot;stand&quot;) 9.10.2 Respecifying Correlated Errors Another route to improving model fit is to allow error covariances. Lets return to those original modification indices from the corrF specification. lavaan::modindices(corrF, sort=TRUE, minimum.value = 4) lhs op rhs mi epc sepc.lv sepc.all sepc.nox 58 AS =~ AF4 23.028 0.317 0.308 0.242 0.242 97 MI =~ AF3 12.480 0.586 0.263 0.200 0.200 298 AF3 ~~ MI1 12.241 0.137 0.137 0.250 0.250 95 MI =~ AF1 10.763 -0.494 -0.222 -0.180 -0.180 116 AUA =~ MI1 8.611 -0.201 -0.137 -0.183 -0.183 76 AF =~ AS9 8.120 0.179 0.181 0.150 0.150 78 AF =~ MI2 7.700 -0.113 -0.114 -0.169 -0.169 86 MI =~ AS1 7.630 -0.363 -0.163 -0.134 -0.134 85 AF =~ AUA4 7.523 0.134 0.135 0.157 0.157 96 MI =~ AF2 6.572 0.409 0.184 0.149 0.149 77 AF =~ MI1 6.560 0.116 0.117 0.157 0.157 320 MI1 ~~ AUA1 5.644 -0.058 -0.058 -0.200 -0.200 98 MI =~ AF4 5.598 -0.399 -0.179 -0.141 -0.141 55 AS =~ AF1 5.092 -0.133 -0.129 -0.105 -0.105 109 AUA =~ AS7 4.996 -0.158 -0.108 -0.112 -0.112 114 AUA =~ AF3 4.473 -0.207 -0.141 -0.107 -0.107 108 AUA =~ AS6 4.294 0.149 0.102 0.107 0.107 63 AS =~ MI5 4.263 0.079 0.077 0.123 0.123 117 AUA =~ MI2 4.153 0.126 0.086 0.126 0.126 92 MI =~ AS7 4.135 0.243 0.109 0.114 0.114 288 AF2 ~~ MI1 4.091 0.077 0.077 0.141 0.141 The highest item to item (as opposed to factor to item) modification index is AF3 and MI1. If we allow these to covary the overall chi-square will be reduced by 12 points. Generally, a 1 degree of freedom change in a model will be a statistically significant difference if the chi-square value drops by 4 points, so we can expect this to make a statistically significant difference. In CFA models, freeing the errors of the items to covary means that there is something in common between the items that is not explained by their relationship to the factor (or, factors, if they are assigned to different factors). It is important to consider (theoretically, rationally) what might be shared between the items. It could be content; it could be a methods factor (e.g., reverse-scored items). AF3: Others take romantic interest in AAW just because they never had sex with an AAW before. MI1: I see non-Asian women being casted to play female Asian characters. In the context of this instrument whose CFA properties are already strong, I find it difficult to justify allowing these errors to covary, but I want to demonstrate the technique. We respecify it by adding ModInd_M2 &lt;- &#39;AS =~ AS1 + AS2 + AS3 + AS4 + AS5 + AS6 + AS7 + AS8 + AS9 AF =~ AF1 + AF2 + AF3 + AF4 MI =~ MI1 + MI2 + MI3 + MI4 + MI5 AUA =~ AUA1 + AUA2 + AUA3 + AUA4 #freeing errors to covary by specifying a covariance AF3~~MI1 &#39; ModInd_M2 [1] &quot;AS =~ AS1 + AS2 + AS3 + AS4 + AS5 + AS6 + AS7 + AS8 + AS9\\n AF =~ AF1 + AF2 + AF3 + AF4 \\n MI =~ MI1 + MI2 + MI3 + MI4 + MI5\\n AUA =~ AUA1 + AUA2 + AUA3 + AUA4 \\n \\n #freeing errors to covary by specifying a covariance\\n AF3~~MI1\\n\\n &quot; ModInd_M2f &lt;- lavaan::cfa(ModInd_M2, data = dfGRMSAAW) lavaan::summary(ModInd_M2f, fit.measures = TRUE, standardized = TRUE) lavaan 0.6-9 ended normally after 38 iterations Estimator ML Optimization method NLMINB Number of model parameters 51 Number of observations 304 Model Test User Model: Test statistic 207.790 Degrees of freedom 202 P-value (Chi-square) 0.375 Model Test Baseline Model: Test statistic 2114.899 Degrees of freedom 231 P-value 0.000 User Model versus Baseline Model: Comparative Fit Index (CFI) 0.997 Tucker-Lewis Index (TLI) 0.996 Loglikelihood and Information Criteria: Loglikelihood user model (H0) -8435.341 Loglikelihood unrestricted model (H1) -8331.446 Akaike (AIC) 16972.682 Bayesian (BIC) 17162.250 Sample-size adjusted Bayesian (BIC) 17000.504 Root Mean Square Error of Approximation: RMSEA 0.010 90 Percent confidence interval - lower 0.000 90 Percent confidence interval - upper 0.027 P-value RMSEA &lt;= 0.05 1.000 Standardized Root Mean Square Residual: SRMR 0.057 Parameter Estimates: Standard errors Standard Information Expected Information saturated (h1) model Structured Latent Variables: Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all AS =~ AS1 1.000 0.971 0.798 AS2 0.626 0.047 13.209 0.000 0.608 0.723 AS3 0.913 0.070 12.953 0.000 0.886 0.711 AS4 1.084 0.083 13.046 0.000 1.053 0.716 AS5 0.966 0.081 11.953 0.000 0.938 0.665 AS6 0.626 0.055 11.388 0.000 0.608 0.638 AS7 0.658 0.055 12.006 0.000 0.639 0.668 AS8 0.755 0.066 11.394 0.000 0.734 0.638 AS9 0.736 0.071 10.427 0.000 0.714 0.591 AF =~ AF1 1.000 1.022 0.827 AF2 0.806 0.074 10.835 0.000 0.824 0.668 AF3 0.900 0.079 11.455 0.000 0.919 0.706 AF4 0.801 0.077 10.469 0.000 0.818 0.644 MI =~ MI1 1.000 0.422 0.568 MI2 0.901 0.158 5.708 0.000 0.380 0.560 MI3 0.865 0.158 5.479 0.000 0.365 0.506 MI4 0.846 0.159 5.323 0.000 0.357 0.479 MI5 0.526 0.121 4.356 0.000 0.222 0.356 AUA =~ AUA1 1.000 0.682 0.817 AUA2 0.876 0.089 9.795 0.000 0.597 0.748 AUA3 0.635 0.083 7.628 0.000 0.433 0.504 AUA4 0.630 0.083 7.552 0.000 0.430 0.498 Covariances: Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all .AF3 ~~ .MI1 0.144 0.040 3.582 0.000 0.144 0.255 AS ~~ AF 0.019 0.066 0.290 0.772 0.019 0.019 MI 0.037 0.031 1.172 0.241 0.090 0.090 AUA 0.023 0.045 0.520 0.603 0.035 0.035 AF ~~ MI -0.041 0.035 -1.193 0.233 -0.096 -0.096 AUA 0.018 0.049 0.370 0.711 0.026 0.026 MI ~~ AUA 0.027 0.023 1.161 0.246 0.094 0.094 Variances: Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all .AS1 0.536 0.055 9.729 0.000 0.536 0.363 .AS2 0.338 0.032 10.713 0.000 0.338 0.477 .AS3 0.767 0.071 10.819 0.000 0.767 0.494 .AS4 1.057 0.098 10.781 0.000 1.057 0.488 .AS5 1.110 0.099 11.162 0.000 1.110 0.558 .AS6 0.539 0.048 11.319 0.000 0.539 0.593 .AS7 0.508 0.046 11.146 0.000 0.508 0.554 .AS8 0.782 0.069 11.318 0.000 0.782 0.592 .AS9 0.950 0.082 11.540 0.000 0.950 0.650 .AF1 0.481 0.076 6.359 0.000 0.481 0.315 .AF2 0.841 0.083 10.085 0.000 0.841 0.554 .AF3 0.852 0.090 9.470 0.000 0.852 0.502 .AF4 0.943 0.091 10.372 0.000 0.943 0.585 .MI1 0.373 0.042 8.857 0.000 0.373 0.677 .MI2 0.316 0.035 9.030 0.000 0.316 0.686 .MI3 0.386 0.039 9.859 0.000 0.386 0.744 .MI4 0.428 0.042 10.202 0.000 0.428 0.770 .MI5 0.341 0.030 11.312 0.000 0.341 0.874 .AUA1 0.231 0.044 5.256 0.000 0.231 0.332 .AUA2 0.281 0.038 7.313 0.000 0.281 0.441 .AUA3 0.551 0.049 11.216 0.000 0.551 0.746 .AUA4 0.559 0.050 11.250 0.000 0.559 0.752 AS 0.943 0.117 8.071 0.000 1.000 1.000 AF 1.044 0.134 7.786 0.000 1.000 1.000 MI 0.178 0.043 4.107 0.000 1.000 1.000 AUA 0.464 0.066 6.991 0.000 1.000 1.000 9.10.2.1 Interpreting the Output Criteria Our Results Criteria met? Factor loadings significant, strong, proper valence AS: .59 to .80; AF: .64 to .83; MI: .36 to .57; AUA: 50 to .82 Yes Non-significant chi-square \\(\\chi ^{2}(202) = 207.790, p = .375\\) Yes \\(CFI\\geq .95\\) CFI = .997 Yes \\(RMSEA\\leq .05\\) (but definitely &lt; .10) RMSEA = .010, 90%CI(.000, .027) Yes \\(SRMR\\leq .08\\) (but definitely &lt; .10) SRMR = .057 Yes Combination rule: \\(CFI \\geq .95\\) and \\(SRMR \\leq .08\\) CFI = .997, SRMR = .057 Yes We can formally test the difference in models. I do not include the earlier respecification because (a) it wasnt justifiable and (b) unless I added this error covariance (to the factor loading), it would have the same degrees of freedom and no difference could be tested with the chi-square difference test. lavaan::lavTestLRT(uncorrF, corrF, ModInd_M2f) Chi-Squared Difference Test Df AIC BIC Chisq Chisq diff Df diff Pr(&gt;Chisq) ModInd_M2f 202 16973 17162 207.79 corrF 203 16984 17170 220.86 13.0686 1 0.0003003 *** uncorrF 209 16975 17138 223.70 2.8432 6 0.8282538 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 AIC and BIC are flexible to compare nested and non-nested models. Models with the lower values are superior. They both favor the the model that allows the errors to covary. The \\(\\chi_{D}^{2}\\) can only be used for nested models (where items/indicators are identical  the only difference is the presence/absence of parameters). If it is statistically significant, the better model is the one with the lower chi-square value. This, too, favors the correlated factors model, \\((202) = 207.790, p = .375\\). Diagramming this model helps further clarify how, by freeing the errors to covary, that we have allowed the items to be related outside of their relationship with the rest of the model. semPlot::semPaths(ModInd_M2f, layout = &quot;tree&quot;, style = &quot;lisrel&quot;, what = &quot;col&quot;, whatLabels = &quot;stand&quot;) After each step, we should look again for modification indices. lavaan::modindices(ModInd_M2f, sort = TRUE, minimum.value = 4) lhs op rhs mi epc sepc.lv sepc.all sepc.nox 59 AS =~ AF4 22.971 0.315 0.306 0.241 0.241 77 AF =~ AS9 8.421 0.181 0.184 0.153 0.153 97 MI =~ AF2 8.196 0.498 0.210 0.170 0.170 87 MI =~ AS1 7.716 -0.391 -0.165 -0.136 -0.136 86 AF =~ AUA4 7.502 0.132 0.135 0.157 0.157 289 AF2 ~~ MI1 7.321 0.104 0.104 0.186 0.186 96 MI =~ AF1 6.664 -0.427 -0.180 -0.146 -0.146 117 AUA =~ MI1 6.178 -0.167 -0.114 -0.153 -0.153 79 AF =~ MI2 6.012 -0.101 -0.103 -0.152 -0.152 56 AS =~ AF1 5.724 -0.141 -0.137 -0.111 -0.111 98 MI =~ AF3 5.625 0.450 0.190 0.146 0.146 110 AUA =~ AS7 4.980 -0.158 -0.107 -0.112 -0.112 320 MI1 ~~ AUA1 4.435 -0.050 -0.050 -0.171 -0.171 109 AUA =~ AS6 4.285 0.149 0.102 0.107 0.107 99 MI =~ AF4 4.096 -0.368 -0.155 -0.122 -0.122 94 MI =~ AS8 4.078 0.319 0.135 0.117 0.117 64 AS =~ MI5 4.062 0.077 0.075 0.120 0.120 93 MI =~ AS7 4.042 0.258 0.109 0.114 0.114 Not surprisingly, it points us back to the AS =~AF4 relationship. We have already respecified this and, upon evaluation, decided to reject it. Side by side comparison of correlated, uncorrelated models, cross-loading, and errors freed models Looking at the models side-by-side, we can continue to thinking about the nested-to-nesting continum. The uncorrF (upper left) model is nested (fewer specified parameters, higher degrees of freedom) is nested in the corrF model (upper right) is nested. Our initial comparison was of these two models. We expected corrF to have superior fit, however, the unique characteristics of the simulated data surprised us! We then compared the corrF model to the two models below. In these comparisons corrF was nested in each of the lower models which had one parameter freed (the cross-loading on the lower left; the error covariance on the lower right). As is common, each of these nesting models (more parameters, fewer degrees of freedom) had better fit. However, because the additions were not theoretically justifiable (and the fit for corrF and uncorrF was satisfatory), we did not retain these respecifications. Think back to the dont break the ice analogy  freeing all those parameters gets closer to the just-identified circumstance where all the relations in the sample covariance matrix are allowed to relate to each other (none are set to 0.0 or knocked out of the ice frame). Source: https://www.flickr.com/photos/arfsb/4407495674 9.11 Modeling the GRMSAAW as a Second-Order Structure Another approach to model building is to explore alternative factor structures. Lets investigate a second-order model. A second-order model represents the hypothesis that a second-order factor, g, causes each of the identified first-order factors. Note that: the first-order factors have indicators, but the general factor has none; that is, the second-order factor is measured only indirectly through the indicators of the first-order factors the specification of g as a common cause of the lower order factors implies that any additional association between the first-order factors is spurious there must be at least three first-order factors or their disturbance variances may be underidentified; each first-order factor should have at least two indicators; more is better two options for scaling g fixing the direct of effect of g on one factor (usually the first or last) to 1.0; or fixing the variance of g to 1.0 (standardizing it); this leaves all direct effects of g on the first-order factors as free parameters In our second-order model, we will add an the overall GRMS factor as our g below the four existing factors. secondM &lt;- &#39;AS =~ AS1 + AS2 + AS3 + AS4 + AS5 + AS6 + AS7 + AS8 + AS9 AF =~ AF1 + AF2 + AF3 + AF4 MI =~ MI1 + MI2 + MI3 + MI4 + MI5 AUA =~ AUA1 + AUA2 + AUA3 + AUA4 GRMS =~ AS + AF + MI + AUA&#39; secondM [1] &quot;AS =~ AS1 + AS2 + AS3 + AS4 + AS5 + AS6 + AS7 + AS8 + AS9\\n AF =~ AF1 + AF2 + AF3 + AF4 \\n MI =~ MI1 + MI2 + MI3 + MI4 + MI5\\n AUA =~ AUA1 + AUA2 + AUA3 + AUA4\\n GRMS =~ AS + AF + MI + AUA&quot; secondF &lt;- lavaan::cfa (secondM, data = dfGRMSAAW) Warning in lav_object_post_check(object): lavaan WARNING: some estimated lv variances are negative lavaan::summary(secondF, fit.measures = TRUE, standardized = TRUE, rsquare = TRUE) lavaan 0.6-9 ended normally after 138 iterations Estimator ML Optimization method NLMINB Number of model parameters 48 Number of observations 304 Model Test User Model: Test statistic 221.237 Degrees of freedom 205 P-value (Chi-square) 0.208 Model Test Baseline Model: Test statistic 2114.899 Degrees of freedom 231 P-value 0.000 User Model versus Baseline Model: Comparative Fit Index (CFI) 0.991 Tucker-Lewis Index (TLI) 0.990 Loglikelihood and Information Criteria: Loglikelihood user model (H0) -8442.065 Loglikelihood unrestricted model (H1) -8331.446 Akaike (AIC) 16980.129 Bayesian (BIC) 17158.547 Sample-size adjusted Bayesian (BIC) 17006.315 Root Mean Square Error of Approximation: RMSEA 0.016 90 Percent confidence interval - lower 0.000 90 Percent confidence interval - upper 0.030 P-value RMSEA &lt;= 0.05 1.000 Standardized Root Mean Square Residual: SRMR 0.059 Parameter Estimates: Standard errors Standard Information Expected Information saturated (h1) model Structured Latent Variables: Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all AS =~ AS1 1.000 0.971 0.798 AS2 0.627 0.047 13.208 0.000 0.608 0.723 AS3 0.913 0.070 12.952 0.000 0.886 0.711 AS4 1.085 0.083 13.049 0.000 1.053 0.716 AS5 0.966 0.081 11.945 0.000 0.938 0.665 AS6 0.626 0.055 11.385 0.000 0.608 0.638 AS7 0.658 0.055 12.015 0.000 0.639 0.668 AS8 0.756 0.066 11.393 0.000 0.734 0.638 AS9 0.735 0.071 10.413 0.000 0.714 0.591 AF =~ AF1 1.000 1.014 0.821 AF2 0.824 0.075 10.937 0.000 0.836 0.678 AF3 0.934 0.081 11.499 0.000 0.947 0.720 AF4 0.801 0.077 10.349 0.000 0.812 0.639 MI =~ MI1 1.000 0.449 0.599 MI2 0.847 0.145 5.846 0.000 0.381 0.561 MI3 0.811 0.145 5.595 0.000 0.364 0.506 MI4 0.797 0.146 5.441 0.000 0.358 0.481 MI5 0.491 0.112 4.397 0.000 0.221 0.353 AUA =~ AUA1 1.000 0.683 0.819 AUA2 0.875 0.089 9.780 0.000 0.597 0.748 AUA3 0.633 0.083 7.614 0.000 0.432 0.503 AUA4 0.627 0.083 7.523 0.000 0.428 0.496 GRMS =~ AS 1.000 0.075 0.075 AF -0.752 1.217 -0.618 0.537 -0.054 -0.054 MI 6.794 60.817 0.112 0.911 1.097 1.097 AUA 0.663 0.917 0.723 0.470 0.070 0.070 Variances: Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all .AS1 0.537 0.055 9.731 0.000 0.537 0.363 .AS2 0.338 0.032 10.712 0.000 0.338 0.477 .AS3 0.767 0.071 10.817 0.000 0.767 0.494 .AS4 1.056 0.098 10.779 0.000 1.056 0.488 .AS5 1.111 0.100 11.164 0.000 1.111 0.558 .AS6 0.539 0.048 11.319 0.000 0.539 0.593 .AS7 0.507 0.046 11.143 0.000 0.507 0.554 .AS8 0.782 0.069 11.317 0.000 0.782 0.592 .AS9 0.951 0.082 11.543 0.000 0.951 0.651 .AF1 0.496 0.076 6.551 0.000 0.496 0.326 .AF2 0.821 0.083 9.933 0.000 0.821 0.540 .AF3 0.833 0.090 9.231 0.000 0.833 0.482 .AF4 0.953 0.092 10.409 0.000 0.953 0.591 .MI1 0.361 0.043 8.374 0.000 0.361 0.641 .MI2 0.316 0.035 9.081 0.000 0.316 0.685 .MI3 0.386 0.039 9.916 0.000 0.386 0.744 .MI4 0.427 0.042 10.232 0.000 0.427 0.769 .MI5 0.342 0.030 11.350 0.000 0.342 0.875 .AUA1 0.230 0.044 5.201 0.000 0.230 0.330 .AUA2 0.281 0.038 7.297 0.000 0.281 0.441 .AUA3 0.551 0.049 11.224 0.000 0.551 0.747 .AUA4 0.560 0.050 11.264 0.000 0.560 0.754 .AS 0.938 0.125 7.476 0.000 0.994 0.994 .AF 1.025 0.136 7.555 0.000 0.997 0.997 .MI -0.041 2.170 -0.019 0.985 -0.204 -0.204 .AUA 0.464 0.069 6.673 0.000 0.995 0.995 GRMS 0.005 0.048 0.110 0.912 1.000 1.000 R-Square: Estimate AS1 0.637 AS2 0.523 AS3 0.506 AS4 0.512 AS5 0.442 AS6 0.407 AS7 0.446 AS8 0.408 AS9 0.349 AF1 0.674 AF2 0.460 AF3 0.518 AF4 0.409 MI1 0.359 MI2 0.315 MI3 0.256 MI4 0.231 MI5 0.125 AUA1 0.670 AUA2 0.559 AUA3 0.253 AUA4 0.246 AS 0.006 AF 0.003 MI NA AUA 0.005 9.11.1 Interpreting the Output Criteria Our Results Criteria met? Factor loadings significant, strong, proper valence 59 to .80; AF: .64 to .83; MI: .36 to .57; AUA: .50 to .82; GRMS: -.054 to 1.097) Yes Non-significant chi-square \\(\\chi ^{2}(205) = 221.237, p = .208\\) Yes \\(CFI\\geq .95\\) CFI = .991 Yes \\(RMSEA\\leq .05\\) (but definitely &lt; .10) RMSEA = .016, 90%CI(.000, .030) Yes \\(SRMR\\leq .08\\) (but definitely &lt; .10) SRMR = .059 Yes Combination rule: \\(CFI \\geq .95\\) and \\(SRMR \\leq .08\\) CFI = .991, SRS = .059 Yes 9.11.2 Partial Write-up Second-order factor model. Our next model represented a second order structure. Specifically, four first-order factors loaded onto a second factor model demonstrated adequate fit to the data: $^{2}(205) = 221.237, p = .208, RMSEA = .016, 90%CI(.000, .030), SRMR = .059. Factor loadings ranged from .59 to .80 for the AS scale, .64 to .83 for the AF scale, .35 to .57 for the MI scale, .50 to .82 for the fear of AUA scale, and -.054 to 1.097 for the GRMS total scale. As we plot this model we expect to see a second level factor predicting each of the first order factors. The indicator was set on GRM &gt; AS. Each of the four factors predicts only the items associated with their factor with one item for each factor (the first on the left) specified as the indicator variable. semPlot::semPaths(secondF, layout = &quot;tree&quot;, style = &quot;lisrel&quot;, what = &quot;col&quot;, whatLabels = &quot;stand&quot;) Determining if models are nested vs.Â hierarchically-arranged can be confusing, especially when it comes to adding in second-order structures. That is, replacing the six correlations (in the correlated factors model) with the second-order factor (fixing the first of the first-order factors to 1.0, so adding only 3 paths to be estimated) is not a clear fixing or freeing of paths. We need to know if they are so that we know if it is appropriate to apply/interpret the \\(\\chi_{D}^{2}\\) difference test. Luckily, the Muthens (creators of Mplus) have a discussion post devoted to this and it appears that our correlated factors model is the nesting model for the second-order structure. If there is a statistically significant difference in models, then the correlated factors model is superior. lavaan::lavTestLRT(uncorrF, corrF, secondF) Chi-Squared Difference Test Df AIC BIC Chisq Chisq diff Df diff Pr(&gt;Chisq) corrF 203 16984 17170 220.86 secondF 205 16980 17159 221.24 0.37923 2 0.8273 uncorrF 209 16975 17138 223.70 2.46397 4 0.6511 Although there is not a statistically significant chi-square difference test (\\(\\chi^{2}(2) = .37923, p = .827\\), the AIC and BIC favor the second-order model. If our model fit was poor, we would want to inspect the modification indices and see if it would be justifiable to allow error covariances. lavaan::modindices(secondF, sort=TRUE, minimum.value = 4) lhs op rhs mi epc sepc.lv sepc.all sepc.nox 57 AS =~ AF4 23.014 0.314 0.304 0.240 0.240 131 GRMS =~ AF3 12.910 3.359 0.244 0.185 0.185 96 MI =~ AF3 12.508 0.586 0.263 0.200 0.200 133 GRMS =~ MI1 12.224 92.203 6.694 8.924 8.924 319 AF3 ~~ MI1 12.125 0.136 0.136 0.249 0.249 94 MI =~ AF1 10.802 -0.494 -0.222 -0.180 -0.180 129 GRMS =~ AF1 10.779 -2.784 -0.202 -0.164 -0.164 115 AUA =~ MI1 8.696 -0.202 -0.138 -0.184 -0.184 75 AF =~ AS9 8.190 0.179 0.182 0.150 0.150 77 AF =~ MI2 7.811 -0.114 -0.115 -0.170 -0.170 84 AF =~ AUA4 7.635 0.134 0.135 0.157 0.157 120 GRMS =~ AS1 7.618 -2.047 -0.149 -0.122 -0.122 85 MI =~ AS1 7.611 -0.363 -0.163 -0.134 -0.134 130 GRMS =~ AF2 6.567 2.307 0.167 0.136 0.136 95 MI =~ AF2 6.559 0.409 0.184 0.149 0.149 76 AF =~ MI1 6.538 0.116 0.117 0.156 0.156 132 GRMS =~ AF4 5.995 -2.328 -0.169 -0.133 -0.133 341 MI1 ~~ AUA1 5.610 -0.058 -0.058 -0.200 -0.200 97 MI =~ AF4 5.588 -0.398 -0.179 -0.141 -0.141 108 AUA =~ AS7 4.734 -0.153 -0.104 -0.109 -0.109 107 AUA =~ AS6 4.490 0.152 0.104 0.109 0.109 62 AS =~ MI5 4.257 0.079 0.077 0.123 0.123 126 GRMS =~ AS7 4.201 1.382 0.100 0.105 0.105 116 AUA =~ MI2 4.194 0.126 0.086 0.127 0.127 54 AS =~ AF1 4.144 -0.114 -0.111 -0.090 -0.090 134 GRMS =~ MI2 4.128 -48.152 -3.496 -5.152 -5.152 91 MI =~ AS7 4.118 0.243 0.109 0.114 0.114 113 AUA =~ AF3 4.027 -0.192 -0.131 -0.100 -0.100 309 AF2 ~~ MI1 4.013 0.076 0.076 0.140 0.140 The same AF4 &gt; AS relationship is showing as the item that has a larger modification index than the others. As we saw earlier, freeing it to covary would improve the fit. However, three of our more parsimonious models (uncorrelated factors, correlated factors, seond-order) have excellent fit. Therefore, we will not respecify at this time. 9.12 Modeling the GRMSAAW as a Bifactor Model Bifactor models are also known as nested-factor and general-specific models. Like the second-order model, they involve several specific, correlated constructs that make up a more general construct of interest. The big difference: g in the bifactor model directly affects the indicators but is orthogonal/unrelated to the specific factors bifactor models where g covaries with the specific factors may not be identified bifactor models partition variance into three nonoverlapping sources: specific factors the general factor (g) error If we peek back at Figure ??????, the disturbances in a second-order model resemble the specific factors in a bifactor model, in that both sets of variables are independent of g. Second-order and bifactor models make very different assumptions about whether g is unrelated to the other factors (bifactor model) or covaries with/mediates those other factors (second-order model). Take note that the base factor structure for the bifactor model is identical to the second-order structure. The difference is in the next set of script that fixes the relations between g and each of the factors to 0.0; and the relations between each of the factors to each other as 0.0. bifacM &lt;- &#39; GRMS =~ AS1 + AS2 + AS3 + AS4 + AS5 + AS6 + AS7 + AS8 + AS9 + AF1 + AF2 + AF3 + AF4 + MI1 + MI2 + MI3 + MI4 + MI5 + AUA1 + AUA2 + AUA3 + AUA4 AS =~ AS1 + AS2 + AS3 + AS4 + AS5 + AS6 + AS7 + AS8 + AS9 AF =~ AF1 + AF2 + AF3 + AF4 MI =~ MI1 + MI2 + MI3 + MI4 + MI5 AUA =~ AUA1 + AUA2 + AUA3 + AUA4 #fixes the relations between g and each of the factors to 0.0 GRMS ~~ 0*AS GRMS ~~ 0*AF GRMS ~~ 0*MI GRMS ~~ 0*AUA #fixes the relations (covariances) between each of the factors to 0.0 AS ~~ 0*AF AS ~~ 0*MI AS ~~ 0*AUA AF ~~ 0*MI AF ~~ 0*AUA MI ~~ 0*AUA &#39; bifacM [1] &quot; GRMS =~ AS1 + AS2 + AS3 + AS4 + AS5 + AS6 + AS7 + AS8 + AS9 + AF1 + AF2 + AF3 + AF4 + MI1 + MI2 + MI3 + MI4 + MI5 + AUA1 + AUA2 + AUA3 + AUA4\\n\\n AS =~ AS1 + AS2 + AS3 + AS4 + AS5 + AS6 + AS7 + AS8 + AS9\\n AF =~ AF1 + AF2 + AF3 + AF4 \\n MI =~ MI1 + MI2 + MI3 + MI4 + MI5\\n AUA =~ AUA1 + AUA2 + AUA3 + AUA4\\n \\n #fixes the relations between g and each of the factors to 0.0 \\n GRMS ~~ 0*AS\\n GRMS ~~ 0*AF\\n GRMS ~~ 0*MI\\n GRMS ~~ 0*AUA\\n \\n #fixes the relations (covariances) between each of the factors to 0.0\\n AS ~~ 0*AF\\n AS ~~ 0*MI\\n AS ~~ 0*AUA\\n AF ~~ 0*MI\\n AF ~~ 0*AUA\\n MI ~~ 0*AUA\\n&quot; #On the first run I received a warning; it is not uncommon to add the statement &quot;check.gradient=FALSE&quot; to force a solution. Then it is important to closely inspect the results to see if things look ok. #If you get really stuck it is possible to change optimizers through control statements bifacF &lt;- lavaan::cfa(bifacM, data = dfGRMSAAW, check.gradient=FALSE) Warning in lav_model_vcov(lavmodel = lavmodel, lavsamplestats = lavsamplestats, : lavaan WARNING: Could not compute standard errors! The information matrix could not be inverted. This may be a symptom that the model is not identified. Warning in lav_object_post_check(object): lavaan WARNING: some estimated ov variances are negative lavaan::summary(bifacF, fit.measures = TRUE, standardized = TRUE, rsquare = TRUE) lavaan 0.6-9 ended normally after 2275 iterations Estimator ML Optimization method NLMINB Number of model parameters 66 Number of observations 304 Model Test User Model: Test statistic 164.080 Degrees of freedom 187 P-value (Chi-square) 0.885 Model Test Baseline Model: Test statistic 2114.899 Degrees of freedom 231 P-value 0.000 User Model versus Baseline Model: Comparative Fit Index (CFI) 1.000 Tucker-Lewis Index (TLI) 1.015 Loglikelihood and Information Criteria: Loglikelihood user model (H0) -8413.486 Loglikelihood unrestricted model (H1) -8331.446 Akaike (AIC) 16958.972 Bayesian (BIC) 17204.296 Sample-size adjusted Bayesian (BIC) 16994.977 Root Mean Square Error of Approximation: RMSEA 0.000 90 Percent confidence interval - lower 0.000 90 Percent confidence interval - upper 0.013 P-value RMSEA &lt;= 0.05 1.000 Standardized Root Mean Square Residual: SRMR 0.055 Parameter Estimates: Standard errors Standard Information Expected Information saturated (h1) model Structured Latent Variables: Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all GRMS =~ AS1 1.000 0.000 0.000 AS2 6.287 NA 0.001 0.001 AS3 649.686 NA 0.120 0.096 AS4 713.320 NA 0.131 0.089 AS5 295.575 NA 0.054 0.039 AS6 615.070 NA 0.113 0.118 AS7 920.862 NA 0.169 0.176 AS8 881.728 NA 0.162 0.141 AS9 24.889 NA 0.005 0.004 AF1 -1162.738 NA -0.214 -0.173 AF2 559.380 NA 0.103 0.084 AF3 775.561 NA 0.143 0.109 AF4 -1279.416 NA -0.235 -0.185 MI1 2437.703 NA 0.449 0.598 MI2 2151.253 NA 0.396 0.583 MI3 1972.108 NA 0.363 0.504 MI4 1882.466 NA 0.346 0.465 MI5 485.133 NA 0.089 0.143 AUA1 61.289 NA 0.011 0.014 AUA2 28.496 NA 0.005 0.007 AUA3 508.232 NA 0.094 0.109 AUA4 668.859 NA 0.123 0.143 AS =~ AS1 1.000 0.983 0.808 AS2 0.623 NA 0.612 0.727 AS3 0.900 NA 0.884 0.707 AS4 1.070 NA 1.051 0.712 AS5 0.955 NA 0.939 0.665 AS6 0.616 NA 0.606 0.633 AS7 0.647 NA 0.636 0.661 AS8 0.743 NA 0.730 0.632 AS9 0.729 NA 0.717 0.593 AF =~ AF1 1.000 1.005 0.814 AF2 0.846 NA 0.850 0.690 AF3 0.969 NA 0.974 0.741 AF4 0.791 NA 0.795 0.626 MI =~ MI1 1.000 0.011 0.015 MI2 0.427 NA 0.005 0.007 MI3 0.705 NA 0.008 0.011 MI4 0.372 NA 0.004 0.006 MI5 629.296 NA 7.082 11.331 AUA =~ AUA1 1.000 0.684 0.820 AUA2 0.875 NA 0.598 0.749 AUA3 0.624 NA 0.427 0.497 AUA4 0.617 NA 0.422 0.489 Covariances: Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all GRMS ~~ AS 0.000 0.000 0.000 AF 0.000 0.000 0.000 MI 0.000 0.000 0.000 AUA 0.000 0.000 0.000 AS ~~ AF 0.000 0.000 0.000 MI 0.000 0.000 0.000 AUA 0.000 0.000 0.000 AF ~~ MI 0.000 0.000 0.000 AUA 0.000 0.000 0.000 MI ~~ AUA 0.000 0.000 0.000 Variances: Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all .AS1 0.514 NA 0.514 0.347 .AS2 0.334 NA 0.334 0.471 .AS3 0.767 NA 0.767 0.491 .AS4 1.057 NA 1.057 0.485 .AS5 1.111 NA 1.111 0.557 .AS6 0.536 NA 0.536 0.585 .AS7 0.494 NA 0.494 0.532 .AS8 0.774 NA 0.774 0.580 .AS9 0.947 NA 0.947 0.649 .AF1 0.467 NA 0.467 0.307 .AF2 0.787 NA 0.787 0.518 .AF3 0.761 NA 0.761 0.440 .AF4 0.926 NA 0.926 0.574 .MI1 0.361 NA 0.361 0.642 .MI2 0.304 NA 0.304 0.660 .MI3 0.388 NA 0.388 0.746 .MI4 0.434 NA 0.434 0.783 .MI5 -49.773 NA -49.773 -127.415 .AUA1 0.227 NA 0.227 0.327 .AUA2 0.279 NA 0.279 0.438 .AUA3 0.547 NA 0.547 0.741 .AUA4 0.550 NA 0.550 0.740 GRMS 0.000 NA 1.000 1.000 AS 0.966 NA 1.000 1.000 AF 1.011 NA 1.000 1.000 MI 0.000 NA 1.000 1.000 AUA 0.468 NA 1.000 1.000 R-Square: Estimate AS1 0.653 AS2 0.529 AS3 0.509 AS4 0.515 AS5 0.443 AS6 0.415 AS7 0.468 AS8 0.420 AS9 0.351 AF1 0.693 AF2 0.482 AF3 0.560 AF4 0.426 MI1 0.358 MI2 0.340 MI3 0.254 MI4 0.217 MI5 NA AUA1 0.673 AUA2 0.562 AUA3 0.259 AUA4 0.260 9.12.1 Interpreting the Output Criteria Our Results Criteria met? Factor loadings significant, strong, proper valence GRS: -.185 to .60; AS: 59 to .81; AF: .63 to .81; MI: .006 to 11.33; AUA: .49 to .82 MI goes wonky Non-significant chi-square \\(\\chi ^{2}(187) = 164.080, p = .885\\) Yes \\(CFI\\geq .95\\) CFI = 1.000 Yes \\(RMSEA\\leq .05\\) (but definitely &lt; .10) RMSEA = .000, 90%CI(.000, .013 Yes \\(SRMR\\leq .08\\) (but definitely &lt; .10) SRMR = .055 Yes Combination rule: \\(CFI \\geq .95\\) and \\(SRMR \\leq .08\\) CFI = 1.000, SRS = .055 Yes As promised, even in spite of the wiggly factor loadings, the model fit improves. This is another example of the nesting model generally having the best fit. 9.12.2 Partial Write-up Bifactor model. The bifactor model regressed each item on its respective factor while simultaneously regressing each indicator onto an overall GRMS scale. This model had the best fit of those compared thus far: \\(\\chi ^{2}(187) = 164.080, p = .885\\), CFI = 1.000, RMSEA = .000, 90%CI [.000, .013], SRMR = .055. Factor loadings for the four factors ranged from 59 to .81 for the AS scale, .63 to .81 for the AF scale, .006 to 11.33 for the MI scale, and .49 to .82 for the AUA scale. Factor loadings for the overall GRMSAAW (g) ranged from -.185 to .60. Providing a traditional diagram of the bifactor model requires some extra steps. The default from semPlots semPaths() function produces this: semPlot::semPaths(bifacF, layout = &quot;tree&quot;, style = &quot;lisrel&quot;, what = &quot;col&quot;, whatLabels = &quot;stand&quot;) While it is an accurate depiction, I was seeking the traditional illustration. I found some cool at a discussion on SachaEpskamps semPlot repo on Github. We can think of the variables in our model as numbered. The items take the first numbers, followed by g, and then each of the factors. We need to represent them in a matrix of 0s and numbers. Lets start by mapping them out. The top row is the the factors (4), the second row is items (22), the bottom row is g (1) [1, ] 0 0 0 24 0 0 0 0 25 0 0 0 0 0 26 0 0 0 0 0 27 0 0 [2, ] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 [3, ] 0 0 0 0 0 0 0 0 0 0 0 0 28 0 0 0 0 0 0 0 0 0 0 m = matrix (nrow = 3, ncol = 22) m[1, ] = c(0,0,0,0,24,0,0,0,0,0,25,0,0,0,0,26,0,0,0,0,27,0) m[2, ] = 1:22 m[3, ] = c(0,0,0,0,0,0,0,0,0,0,0,23,0,0,0,0,0,0,0,0,0,0) m [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14] [1,] 0 0 0 0 24 0 0 0 0 0 25 0 0 0 [2,] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 [3,] 0 0 0 0 0 0 0 0 0 0 0 23 0 0 [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [1,] 0 26 0 0 0 0 27 0 [2,] 15 16 17 18 19 20 21 22 [3,] 0 0 0 0 0 0 0 0 semPlot::semPaths(bifacF, &quot;model&quot;, &quot;std&quot;, layout = m, residuals = FALSE, exoCov = FALSE) On the basis of this evaluation we are finding all four models to be satisfactory (in terms of fit): the single-order uncorrelated factors (uncorrF), the single-order correlated factors model (corrF), the second order factor (secondF), and the bifactor model (bifacF). We can use lavaans lavTest() function to compare them. No matter the order that we enter them, the function orders them according to their degrees of freedom. lavaan::lavTestLRT(uncorrF, corrF, secondF, bifacF) Chi-Squared Difference Test Df AIC BIC Chisq Chisq diff Df diff Pr(&gt;Chisq) bifacF 187 16959 17204 164.08 corrF 203 16984 17170 220.86 56.778 16 0.000001809 *** secondF 205 16980 17159 221.24 0.379 2 0.8273 uncorrF 209 16975 17138 223.70 2.464 4 0.6511 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 We see that the bifactor outperforms the corrF model. However, we may be interested in knowing how it compares to the secondF model. The two models are statistically significantly different. The lower values of the AIC and Chi square favor the bifactor model; the lower value of the BIC favors the second-order model. lavaan::lavTestLRT(secondF, bifacF) Chi-Squared Difference Test Df AIC BIC Chisq Chisq diff Df diff Pr(&gt;Chisq) bifacF 187 16959 17204 164.08 secondF 205 16980 17159 221.24 57.158 18 0.000005843 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 In the article, Keum et al. (2018) reported the best fit for the bifactor model. They reported strong, significant, and properly valenced loadings for the g factor as well as for each of the group factors. Our wiggly factor loadings on g and the MI scale are likely an artifact of simulating the data from the EFA factor loadings. 9.12.3 Table(s) The semTable package can help us extract the values into a .csv file which will make it easier to create an APA-style table. It takes some tinkering v1 &lt;- c(AS1 = &quot;Others expect me to be submissive&quot;, AS2 = &quot;Others have been surprised when I disagree with them&quot;, AS3 = &quot;Others take my silence as a sign of compliance&quot;, AS4 = &quot;Others have been surprised when I do things independent of my family&quot;, AS5 = &quot;Others have implied that AAW seem content for being a subordinate&quot;, AS6 = &quot;Others treat me as if I will always comply with their requests&quot;, AS7 = &quot;Others expect me to sacrifice my own needs to take care of others (e.g., family, partner) ecause I am an AAW&quot;, AS8 = &quot;Others have hinted that AAW are not assertive enough to be leaders&quot;, AS9 = &quot;Others have hinted that AAW seem to have no desire for leadership&quot;, AF1 = &quot;Others express sexual interest in me because of my Asian appearance&quot;, AF2 = &quot;Others take sexual interest in AAW to fulfill their fantasy&quot;, AF3 = &quot;Others take romantic interest in AAW just because they never had sex with an AAW before&quot;, AF4 = &quot;Others have treated me as if I am always open to sexual advances&quot;, MI1 = &quot;I see non-Asian women being casted to play female Asian characters&quot;, MI2 = &quot;I rarely see AAW playing the lead role in the media&quot;, MI3 = &quot;I rarely see AAW in the media&quot;, MI4 = &quot;I see AAW playing the same type of characters (e.g., Kung Fu woman, sidekick, mistress, tiger mom) in the media&quot;, MI5 = &quot;I see AAW charaters being portrayed as emotionally distanct (e.g., cold-hearted, lack of empathy) in the media&quot;, AUA1 = &quot;Others have talked about AAW as if they all have the same facial features (e.g., eye shape, skin tone)&quot;, AUA2 = &quot;Others have suggested that all AAW look alike&quot;, AUA3 = &quot;Others have talked about AAW as if they all have the same body type (e.g., petite, tiny, small-chested&quot;, AUA4 = &quot;Others have pointed out physical traits in AAW that do not look &#39;Asian&#39;&quot;) grmsAAW_Nested1table &lt;- semTable::semTable(list(&quot;Uncorrelated&quot; = uncorrF, &quot;Correlated&quot; = corrF, &quot;second-order&quot; = secondF, &quot;Bifactor&quot; = bifacF),columns = c(&quot;eststars&quot;), columnLabels = c(eststars = &quot;Estimate&quot;), fits = c(&quot;chisq&quot;, &quot;df&quot;, &quot;pvalue&quot;, &quot;cfi&quot;, &quot;rmsea&quot;, &quot;rmsea.ci.lower&quot;, &quot;rmsea.ci.upper&quot;, &quot;srmr&quot;, &quot;aic&quot;, &quot;bic&quot;), varLabels = v1, file = &quot;grmsAAWNested&quot;, type = &quot;csv&quot;, print.results = FALSE ) #Can change &quot;print.results&quot; to TRUE if you want to see the (messy) output in the .rmd file (it&#39;s easier to read the lavaan output). Lifesaver If, while working with this function you get the error: Error in file(file, ifelse(append,a, w)) : cannot open the connection, its because the .csv file that received your table is still open. R is just trying to write over it. A similar error happens when knitting. 9.13 Another Look at Omega Now that weve had an introduction to CFA/SEM  and the second-order and bifactor models in particular  lets look again the \\(\\omega\\) grouping of reliability estimates. In prior lessons we used the psych packages omegaSem() function with raw data. The package estimated a family of model based estimates that examine the correlations or covariances of the items and decomposed the test variance into that which is common to all items (g, a general factor), specific to some items (f, orthogonal group factors), and unique to each item (confounding s specific, and e error variance). When using raw data or a correlation matrix as the object for the omega analysis, it is possible to specify the number of factors, but the procedure is exploratory and there is no guarantee that the items will associate with the intended factor. When we are concerned with the omega reliability estimates for clearly specified factor structure we can feed our lavaan::cfa models to the psych::omegaFromSem() function and/or the semTools::reliability() function. 9.13.1 Omega h for Bifactor Models In bifactor models the general factor captures the variance common across all items and the specific factors account for what is left over. Specific factors represent what is common across members of that factor, separate from what is claimed by g. In the context of a bifactor model, the reliability measure, \\(\\omega_{h}\\), represents the proportion of total-score variance due to a single, general construct that influences all items, despite the multidimensional nature of the item set (Flora, 2020a, 2020b). Stated in terms of the GRMSAAW, \\(\\omega_{h}\\) represents the extent to which the GRMSAAW total score provides a reliable measure of a construct represented by a general factor that influences all items in a multidimensional scale over and above the AS, AF, MI, and AUA subscales. If we use the psych package, we pass our lavaan::cfa model to the omegaFromSem() function. psych::omegaFromSem(bifacF) The following analyses were done using the lavaan package Omega Hierarchical from a confirmatory model using sem = 4677803 Omega Total from a confirmatory model using sem = 375896.1 With loadings of g F1* F2* F3* F4* h2 u2 p2 AS1 1.0 1.00 2.00 -1.00 0.50 AS2 6.3 0.62 39.91 -38.91 0.99 AS3 649.7 0.90 422093.17 -422092.17 1.00 AS4 713.3 1.07 508826.26 -508825.26 1.00 AS5 295.6 0.96 87365.71 -87364.71 1.00 AS6 615.1 0.62 378311.83 -378310.83 1.00 AS7 920.9 0.65 847987.70 -847986.70 1.00 AS8 881.7 0.74 777445.01 -777444.01 1.00 AS9 24.9 0.73 619.98 -618.98 1.00 AF1- 1162.7 1.00 1351960.75 -1351959.75 1.00 AF2 559.4 -0.85 312906.88 -312905.88 1.00 AF3 775.6 -0.97 601495.54 -601494.54 1.00 AF4- 1279.4 0.79 1636906.67 -1636905.67 1.00 MI1 2437.7 1.00 5942397.31 -5942396.31 1.00 MI2 2151.2 0.43 4627890.79 -4627889.79 1.00 MI3 1972.1 0.70 3889209.00 -3889208.00 1.00 MI4 1882.5 0.37 3543680.21 -3543679.21 1.00 MI5 485.1 629.30 631367.50 -631366.50 0.37 AUA1 61.3 1.00 3757.33 -3756.33 1.00 AUA2 28.5 0.87 812.77 -811.77 1.00 AUA3 508.2 0.62 258300.55 -258299.55 1.00 AUA4 668.9 0.62 447372.75 -447371.75 1.00 With sum of squared loadings of: g F1* F2* F3* F4* 25874722.5 6.1 3.3 396015.2 2.5 The degrees of freedom of the confirmatory model are 187 and the fit is 164.0799 with p = 0.885421 general/max 65.34 max/min = 156232.5 mean percent general = 0.95 with sd = 0.17 and cv of 0.18 Explained Common Variance of the general factor = 0.98 Measures of factor score adequacy g F1* F2* F3* Correlation of scores with factors 3787.46 1.34 1.22 673.41 Multiple R square of scores with factors 14344845.25 1.79 1.49 453480.76 Minimum correlation of factor score estimates 28689689.51 2.57 1.98 906960.52 F4* Correlation of scores with factors 1.15 Multiple R square of scores with factors 1.32 Minimum correlation of factor score estimates 1.63 Total, General and Subset omega for each subset g F1* F2* Omega total for total scores and subscales 375896.06 396560.80 6839322 Omega general for total scores and subscales 4677803.05 396559.56 6839322 Omega group for total scores and subscales 5712.44 1.25 0 F3* F4* Omega total for total scores and subscales 8060656.39 180658.13 Omega general for total scores and subscales 8020497.00 180657.04 Omega group for total scores and subscales 40159.39 1.09 To get the standard sem fit statistics, ask for summary on the fitted object I would expect to get omega values that are similar to the alpha coefficient (0 to &lt; 1.0). Likely owing to the simulated data (data was simulated from pattern matrix coefficients from the EFA where the algorithm maximized the loadings onto the single factor and minimized cross-loadings), these results arent making a lot of sense. This is somewhat consistent with the factor loadings we received when we ran the bifactor model. None-the-less, I wanted to at least demonstrate the procedure for obtaining these values. Here are the definitions associated with the values: \\(\\omega_{h}\\) extracts a higher order factor from the correlation matrix of lower level factors, then applies the Schmid and Leiman (1957) transformation to find the general loadings on the original items. Stated another way, it is a measure of the general factor saturation (g; the amount of variance attributable to one comon factor). The subscript h acknowledges the hierarchical nature of the approach. Our result for the overall (g) test is the nonsensical, \\(\\omega{h} = 4677803\\) \\(\\omega_{t}\\) represents the total reliability of the test (\\(\\omega_{t}\\)). In the psych package, this is calculated from a bifactor model where there is one general g factor (i.e., each item loads on the single general factor), one or more group factors (f), and an item-specific factor (s). Floras article and supplementary materials (Flora, 2020a, 2020b) provide an excellent description and review of how to specify and interpret \\(\\omega_{h}\\) with semTools::reliability(). semTools::reliability(bifacF, return.total=TRUE) GRMS AS AF MI AUA total alpha 0.77763237 0.8813966 0.8051640 0.6240087 0.7304837 0.7776324 omega -0.18836048 0.8868824 0.8171387 22.2792918 0.7390534 1.4220602 omega2 0.06689845 0.8781925 0.8150343 10.1744415 0.7325757 1.4220602 omega3 0.06283303 0.8873467 0.8149513 10.1794880 0.7298354 1.3356417 avevar NA NA NA NA NA 2.5342190 In the case of the bifactor model, the omega2 and omega3 values are the \\(\\omega_{h}\\) estimates. Flora (2020a) indicates that omega2 is calculated using the model-implied variance of the total score in its denominator and omega3 is calculated using the observed sample variance of X. To the degree that these two values are different from each other, we may have concerns. In our data, omega2 = .067 and omega3 = .063. These are quite low. The next columns provide values associated with omega-hierarchical-subscale (Flora, 2020b). These analyses indicate how well a given subscale reliably measures a narrower construct that is independent from the broader higher-order construct that also influences the other subscales. Flora (2020b) notates these as \\(\\omega_{h-ss}\\) (omega-higherarchical-subscale). Specifically, \\(\\omega_{h-ss}\\) represents the proportion of variance in a subscale that is due to the coresponding specific factor, over and above the influence of the general factor. Comparing the relative values to each other can provide some indication of the source of reliable variance. We see that the AS, AF, and AUA factors are considerably higher than the GRMS. Again, likely owing to our manufactured data, the MI value is nonsensible. In bifactor models, the multidimensionality of items (i.e., the existence of factors) is considered to be a nuisance (Flora, 2020b) for the measurement of a broad, general construct. This is different from hierarchical models such as the second-order factor structure. Since we can calculate \\(\\omega_{h}\\) for it, lets look at it, next. 9.13.2 \\(\\omega_{h}\\) for Second Order Models In the second-order structure, the researcher hypothesizes that there is a broad, overarching construct indirectly influencing all items in a test through more conceptually narrow constructs that directly influence different groupings of items. This hypothesis implies that item-level data arise from a higher order model, in which the second-order factor, causes individual differences in the first-order factor, which directly influences the observed item responses. In this case, \\(\\omega_{ho}\\) (ho = higher order) (Flora, 2020b) represents the proportion of total-score variance that is due to the higher-order factor. As such, it represents the reliability of a total score for measuring a single construct that influences all items. psych::omegaFromSem(secondF) The following analyses were done using the lavaan package Omega Hierarchical from a confirmatory model using sem = 0.67 Omega Total from a confirmatory model using sem = 0.92 With loadings of g F1* F2* F3* F4* h2 u2 p2 AS1 1.00 1.00 0.00 1.00 AS2 0.63 0.39 0.61 1.02 AS3 0.91 0.83 0.17 1.00 AS4 1.08 1.18 -0.18 0.99 AS5 0.97 0.93 0.07 1.01 AS6 0.63 0.39 0.61 1.02 AS7 0.66 0.43 0.57 1.01 AS8 0.76 0.57 0.43 1.01 AS9 0.73 0.54 0.46 0.99 AF1 1.00 1.00 0.00 0.00 AF2 0.82 0.68 0.32 0.00 AF3 0.93 0.87 0.13 0.00 AF4 0.80 0.64 0.36 0.00 MI1 1.00 1.00 0.00 0.00 MI2 0.85 0.72 0.28 0.00 MI3 0.81 0.66 0.34 0.00 MI4 0.80 0.63 0.37 0.00 MI5 0.49 0.24 0.76 0.00 AUA1 1.00 1.00 0.00 0.00 AUA2 0.87 0.76 0.24 0.00 AUA3 0.63 0.40 0.60 0.00 AUA4 0.63 0.39 0.61 0.00 With sum of squared loadings of: g F1* F2* F3* F4* 6.3 3.2 3.2 2.6 0.0 The degrees of freedom of the confirmatory model are 205 and the fit is 221.2374 with p = 0.2077121 general/max 1.93 max/min = Inf mean percent general = 0.41 with sd = 0.51 and cv of 1.23 Explained Common Variance of the general factor = 0.41 Measures of factor score adequacy g F1* F2* F3* F4* Correlation of scores with factors 1.35 1.20 1.40 1.15 0 Multiple R square of scores with factors 1.82 1.45 1.96 1.32 0 Minimum correlation of factor score estimates 2.64 1.90 2.92 1.65 -1 Total, General and Subset omega for each subset g F1* F2* F3* F4* Omega total for total scores and subscales 0.92 1.23 1.57 1.11 NA Omega general for total scores and subscales 0.67 1.00 0.00 0.00 NA Omega group for total scores and subscales 0.47 0.23 1.57 1.11 NA To get the standard sem fit statistics, ask for summary on the fitted object To use semTools we switch functions to reliabilityL2. The specification semTools::reliabilityL2(secondF, &#39;GRMS&#39;) omegaL1 omegaL2 partialOmegaL1 0.0684005 0.1159531 0.3112786 Yikes! Whereas we saw an improvement in \\(\\omega_{h}\\) in the psych package, these values stay relatively horrible. Specifically, omegaL1 represents \\(\\omega_{ho}\\), the proportion of GRMSAAW total score variance due to the higher-order factor. We can apply the semTools::reliability() function to the second-order factor to obtain omega values for the subscales. Below the alpha coefficients, the omega values indicate how reliably each subscale measures its lower order factor. For example, 88% of the total variance of a total score comprised of only the 9 items in the AS scale is explained by the AS lower order factor. semTools::reliability(secondF) AS AF MI AUA alpha 0.8813966 0.8051640 0.6240087 0.7304837 omega 0.8859192 0.8075392 0.6320384 0.7383105 omega2 0.8859192 0.8075392 0.6320384 0.7383105 omega3 0.8860104 0.8077555 0.6331148 0.7353215 avevar 0.4731023 0.5140137 0.2639913 0.4235599 9.14 Preparing an APA Style Results Section Model testing. To evaluate the models we, we used confirmatory factor analysis (CFA) in the R package, lavaan (v.0.6-9) with maximum likelihood estimation. Our sample size was 304. We selected fit criteria for their capacity to assess different aspects of the statistical analysis. As is common among SEM researchers, we reported the Chi-square goodness of fit (\\(\\chi^2\\)). This evaluates the discrepancy between the unrestricted sample matrix and the restricted covariance matrix. Although the associated \\(p\\) value indicates adequate fit when the value is non-significant, it is widely recognized that large sample size can result in a statistically significant p value (Byrne, 2016). The comparative fit index (CFI) is an incremental index, comparing the hypothesized modelat least .90 and perhaps higher than .95 (Kline, 2016). The root mean square error of approximation (RMSEA) takes into account the error of approximation in the population and expresses it per degree of freedom. As such, the fit indicator considers the complexity of the model. Ideal values are equal to or less than .05, values less than .08 represent reasonable fit, and values between .08 and .10 represent mediocre fit. The standardized root mean residual (SRMR) is a standardized measure of the mean absolute covariance residual  the overall difference between the observed and predicted correlations. Values greater than .10 may indicate poor fit and inspection of residuals is then advised. Because we were interested in comparing nested models we used the Chi-square difference test where a significant chi-square indicates statistically significant differences in models. Additionally we used Akaikes Information Criterion (AIC) and the Bayesian Information Criterion (BIC) that take model complexity and sample size into consideration. Models with lower values on each are considered to be superior. Kline (2016) advised researchers to be cautious when using these criteria as strict cut-offs. Elements such as sample size and model complexity should be considered when evaluating fit. Table 1 provides a side-by-side comparison of the resulting parameter estimates and fit statistics; Figures 1 and 2 provide a graphic representation of the models tested. To assess the factor structure of the GRMSAAW we examined five separate models: a unidimensional model, an uncorrelated factors model, a correlated factors model, a second-order model, and two bifactor models. Support for a unidimensional model would suggest that the model is best presented by a total scale score with no subfactors. Support for an uncorrelated factors model would suggest that the the factors are largely independent. Support for a correlated factors model would suggest that the factors are related. Support for a second-order GRMS factor would suggest that the AS, AF, MI, and AUA subfactors represent facets of the higher order factor, GRMS. In the bifactor models, items for each scale are loaded onto both their respective subscale and the overall GRMS scale (g). Support for this model would suggest that each subscale has both independent variance, and common variance that belongs to an underlying GRMS factor. If a bifactor model is the best representation of fit to the data, researchers can utilize bifactor indices to determine the proportion of variance accounted for by the subscales and the general factor, respectively. Our first model was unidimensional where each of the 22 items loaded onto a single factor representing overall gendered racial microaggressions for Asian American women. Standardized pattern coefficients ranged between -.030 and .799 and were not all statistically significant. The Chi-square index was statistically signficant (\\(\\chi ^{2}(209)=1004.136, p &lt; .001\\)) indicating likely misfit. The CFI value of .58 indicated poor fit. The RMSEA = .11 (90% CI [.11, .20]) suggested serious problems. The SRMR value of .12 exceeded the warning criteria of .10. The AIC and BIC values were 17755.028 and 17918.577, respectively, and will become useful in comparing subsequent models. Our second model was a single-order, multidimensional model where the factors were constrained to be uncorrelated (i.e., orthogonal). This model demonstrated adequate fit to the data: \\(\\chi ^{2}(209) = 223.70, p = .231\\), CFI = .99, RMSEA = .015, 90%CI(.000, .029), SRMR = .062. Factor loadings ranged from .59 to .80 for the AS scale, .64 to .82 for the AF scale, .35 to .62 for the MI scale, and .49 to .82 for the fear of AUA scale. Our third model was a single-order, multidimensional, correlated factors, model where each of the 22 items loaded onto one of four factors. Standardized pattern coefficients ranged between .59 and .80 on the AF factor, between .64 and .82 on the AS factor, between .35 and .60 on the MI factor, and between .59 and .82 on the AUA factor. The Chi-square index was statistically signficant (\\(\\chi ^{2}(203)=220.858, p &lt; .186\\)) indicating reasonable fit. The CFI value of .99 exceeded the recommendation of .95. The RMSEA = .017 (90% CI [.000, .031]) was satisfactory. The SRMR value of .058 remained below the warning criteria of .10. The AIC and BIC values were 16983.750 and 17169.602, respectively. Our fourth model represented a second order structure. Specifically, four first-order factors loaded onto a second factor modeldemonstrated adequate fit to the data: $^{2}(205) = 221.237, p = .208, RMSEA = .016, 90%CI(.000, .030), SRMR = .059. Factor loadings ranged from .59 to .80 for the AS scale, .64 to .83 for the AF scale, .35 to .57 for the MI scale, Our third model represented a second order structure. Specifically, four first-order factors loaded onto a second factor model demonstrated adequate fit to the data: $^{2}(205) = 221.237, p = .208, RMSEA = .016, 90%CI(.000, .030), SRMR = .059. Factor loadings ranged from .59 to .80 for the AS scale, .64 to .83 for the AF scale, .35 to .57 for the MI scale, .50 to .82 for the fear of AUA scale, and -.054 to 1.097 for the GRMS total scale. The fifth model, a bifactor model, regressed each item on its respective factor while simultaneously regressing each indicator onto an overall GRMS scale. This model had the best fit of those compared thus far: \\(\\chi ^{2}(187) = 164.080, p = .885\\), CFI = 1.000, RMSEA = .000, 90%CI [.000, .013], SRMR = .055. Factor loadings for the four factors ranged from 59 to .81 for the AS scale, .63 to .81 for the AF scale, .006 to 11.33 for the MI scale, and .49 to .82 for the AUA scale. Factor loadings for the overall GRMSAAW (g) ranged from -.185 to .60. As shown in our table of model comparison, the Chi-square difference test (\\(\\chi ^{2}((187) = 164.08, p &lt; .001\\)) was statistically significant and AIC value of the bifactor model lowest. Thus, while all of the multidimensional models demonstrated adequate fit, we conclude the bifactor model is superior and acceptable for use in research and evaluation. Although I demonstrated how to obtain and interpret omega hierarchical, total, and subscales, because the results are nonsensical, I refer you to the Keum article for an example of how to write it up. 9.15 A Conversation with Dr.Â Keum Doctoral student Jadvir Gill (Industrial-Organizational Psychology) and I were able to interview the first author (Brian TaeHyuk Keum, PhD) about the article used for the research vignette (Keum et al., 2018). Heres a direct link to that interview. Among other things, we asked: What challenges did you encounter in the research process and recruiting participants? Can you describe how the items (or subscales) captures intersectional microaggressions for the intended population? How would you like to see the scale used in future science, practice, and advocacy? How do are you using this scale in your current and future research? 9.16 Practice Problems In each of these lessons I provide suggestions for practice that allow you to select one or more problems that are graded in difficulty. The least complex is to change the random seed and rework the problem demonstrated in the lesson. The results should map onto the ones obtained in the lecture. The second option comes from the the back of the book where a chapter contains simulated data for all of the examples worked in this volume. Any of these is available for CFA. As a third option, you are welcome to use data to which you have access and is suitable for CFA. These could include other simualated data, data available through open science repositories, or your own data (presuming you have permissoin to use it). The suggestion for practice spans the prior chapter and this one. For this combination assignment, you should plan to: Prepare the data frame for CFA. Specify and run unidimensional, single order (with correlated factors), second-order, and bifactor models. Narrate the adequacy of fit with \\(\\chi ^{2}\\), CFI, RMSEA, SRMR Write a mini-results section for each Compare model fit with \\(\\chi ^{2}\\Delta\\), AIC, and BIC. Write an APA style results sections with table(s) and figures. 9.16.1 Problem #1: Play around with this simulation. Copy the script for the simulation and then change (at least) one thing in the simulation to see how it impacts the results. Using the lecture and workflow (chart) as a guide, please work through all the steps listed in the proposed assignment/grading rubric. Assignment Component Points Possible Points Earned 1. Prepare data for CFA (items only df, reverse-scored) 5 _____ 2. Specify and run a unidimensional model 5 _____ 3. Narrate adequacy of fit with \\(\\chi ^{2}\\), CFI, RMSEA, SRMR (write a mini-results section) 5 _____ 4. Specify and run a single-order model with correlated factors 5 _____ 5. Narrate adequacy of fit with \\(\\chi ^{2}\\), CFI, RMSEA, SRMR (write a mini-results section) 5 _____ 6. Specify and run a second-order model 5 _____ 7. Narrate adequacy of fit with \\(\\chi ^{2}\\), CFI, RMSEA, SRMR (write a mini-results section) 5 _____ 8. Specify and run a bifactor model 5 _____ 9. Narrate adequacy of fit with \\(\\chi ^{2}\\), CFI, RMSEA, SRMR (write a mini-results section) 5 _____ 10. Compare model fit with \\(\\chi ^{2}\\Delta\\), AIC, BIC 5 _____ 11. APA style results with table(s) and figures 5 _____ 12. Explanation to grader 5 _____ Totals 60 _____ 9.16.2 Readings &amp; Resources 9.16.3 Problem #2: Use simulated data from other lessons. The second option comes from the the back of the book where a chapter contains simulated data for all of the examples worked in this volume. Any of these is available for CFA. Assignment Component Points Possible Points Earned 1. Prepare data for CFA (items only df, reverse-scored) 5 _____ 2. Specify and run a unidimensional model 5 _____ 3. Narrate adequacy of fit with \\(\\chi ^{2}\\), CFI, RMSEA, SRMR (write a mini-results section) 5 _____ 4. Specify and run a single-order model with correlated factors 5 _____ 5. Narrate adequacy of fit with \\(\\chi ^{2}\\), CFI, RMSEA, SRMR (write a mini-results section) 5 _____ 6. Specify and run a second-order model 5 _____ 7. Narrate adequacy of fit with \\(\\chi ^{2}\\), CFI, RMSEA, SRMR (write a mini-results section) 5 _____ 8. Specify and run a bifactor model 5 _____ 9. Narrate adequacy of fit with \\(\\chi ^{2}\\), CFI, RMSEA, SRMR (write a mini-results section) 5 _____ 10. Compare model fit with \\(\\chi ^{2}\\Delta\\), AIC, BIC 5 _____ 11. APA style results with table(s) and figures 5 _____ 12. Explanation to grader 5 _____ Totals 60 _____ 9.16.4 Problem #3: Try something entirely new. As a third option, you are welcome to use data to which you have access and is suitable for CFA. These could include other simulated data, data available through open science repositories, or your own data (presuming you have permissoin to use it). In either case, please plan to: Using the lecture and workflow (chart) as a guide, please work through all the steps listed in the proposed assignment/grading rubric. Assignment Component Points Possible Points Earned 1. Prepare data for CFA (items only df, reverse-scored) 5 _____ 2. Specify and run a unidimensional model 5 _____ 3. Narrate adequacy of fit with \\(\\chi ^{2}\\), CFI, RMSEA, SRMR (write a mini-results section) 5 _____ 4. Specify and run a single-order model with correlated factors 5 _____ 5. Narrate adequacy of fit with \\(\\chi ^{2}\\), CFI, RMSEA, SRMR (write a mini-results section) 5 _____ 6. Specify and run a second-order model 5 _____ 7. Narrate adequacy of fit with \\(\\chi ^{2}\\), CFI, RMSEA, SRMR (write a mini-results section) 5 _____ 8. Specify and run a bifactor model 5 _____ 9. Narrate adequacy of fit with \\(\\chi ^{2}\\), CFI, RMSEA, SRMR (write a mini-results section) 5 _____ 10. Compare model fit with \\(\\chi ^{2}\\Delta\\), AIC, BIC 5 _____ 11. APA style results with table(s) and figures 5 _____ 12. Explanation to grader 5 _____ Totals 60 _____ References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
